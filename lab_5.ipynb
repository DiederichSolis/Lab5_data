{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b64d7ad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64d7ad8",
        "outputId": "ccc20dd1-389a-4de4-c9a7-9d6f9d0083e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SNAPSHOT DEL DATASET ===\n",
            "Dimensiones: (7613, 5) \n",
            "\n",
            "Nulos por columna (%):\n",
            " location    33.27\n",
            "keyword      0.80\n",
            "id           0.00\n",
            "text         0.00\n",
            "target       0.00\n",
            "dtype: float64 \n",
            "\n",
            "Distribución de target (conteo):\n",
            " target\n",
            "0    4342\n",
            "1    3271\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "Distribución de target (%):\n",
            " target\n",
            "0    57.03\n",
            "1    42.97\n",
            "Name: proportion, dtype: float64 \n",
            "\n",
            "Muestra de filas (5 o menos):\n",
            "         id      keyword               location  \\\n",
            "2644  3796  destruction                    NaN   \n",
            "2227  3185       deluge                    NaN   \n",
            "5448  7769       police                     UK   \n",
            "132    191   aftershock                    NaN   \n",
            "6845  9810       trauma  Montgomery County, MD   \n",
            "\n",
            "                                                   text  target  \n",
            "2644  So you have a new weapon that can cause un-ima...       1  \n",
            "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
            "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
            "132   Aftershock back to school kick off was great. ...       0  \n",
            "6845  in response to trauma Children of Addicts deve...       0   \n",
            "\n",
            "Aplicando preprocesamiento a la columna 'text' -> 'cleaned_text' ...\n",
            "\n",
            "=== EJEMPLOS ANTES/DESPUÉS (Preprocesamiento) ===\n",
            "\n",
            "RAW  : Morganite Gemstone White Fire Opal 925 Sterling Silver Ring Size 6 R1354 http://t.co/hHpVSAtQXN http://t.co/D12r8XpShy\n",
            "CLEAN: morganite gemstone white fire opal sterling silver ring size r1354\n",
            "\n",
            "RAW  : need to work in an office I can bang all my fav Future jams out loud\n",
            "CLEAN: need work office bang fav future jam loud\n",
            "\n",
            "RAW  : Evacuation order lifted for town of Roosevelt: http://t.co/EDyfo6E2PU http://t.co/M5KxLPKFA1\n",
            "CLEAN: evacuation order lifted town roosevelt\n",
            "\n",
            "RAW  : @kshllcenterpri1 @Progress4Ohio burning down buildings what you mean like when you burnt down those black churches?\n",
            "CLEAN: burning building mean like burnt black church\n",
            "\n",
            "RAW  : Fascinating pics from inside North Korea. Not propaganda not devastation - just people living life. http://t.co/E2Dbcpwd9u\n",
            "CLEAN: fascinating pic inside north korea not propaganda not devastation people living life\n",
            "Archivo preprocesado guardado en: outputs_lab5/tweets_cleaned.csv\n",
            "Top 10 palabras disaster: [('fire', 268), ('news', 139), ('disaster', 121), ('via', 121), ('no', 116), ('california', 115), ('suicide', 112), ('year', 111), ('police', 109), ('u', 108)]\n",
            "Top 10 palabras non-disaster: [('like', 256), ('not', 211), ('get', 185), ('new', 171), ('no', 151), ('u', 151), ('one', 139), ('body', 119), ('time', 104), ('day', 102)]\n",
            "Palabras en común (unigrams): {'rainstorm', 'nh', 'preparedness', 'raid', 'fog', 'america', 'ya', 'inner', 'push', 'protection', 'utc2015', 'certified', 'missed', 'website', 'batting', 'typhoon', 'decision', 'attendance', 'striker', 'c', 'describes', 'fish', 'door', 'economic', 'thus', 'suffered', 'instantly', 'economy', 'drown', 'beauty', 'really', 'tubestrike', 'ronaldo', 'little', 'bus', 'british', 'championship', 'join', 'esp', 'concept', 'river', 'given', 'hurricane', 'wife', 'maximum', 'ugly', 'gadget', 'finnish', 'nj', 'coach', 'rapidly', 'surf', 'fueled', 'outbreak', 'madison', 'resource', 'germ', 'toddler', 'evening', 'hail', 'paint', 'usa', 'no', 'traumatised', 'suffer', 'shook', 'bat', 'cinema', 'blk', 'map', 'explain', 'giant', 'wholesale', 'stabbing', 'protectdenaliwolves', 'big', 'approves', 'g', 'sent', 'oregon', 'pet', 'kosciusko', 'shot', 'lose', 'microphone', '18w', 'back', 'stage', 'roanoke', 'attractive', 'video', 'giving', '8th', 'sadly', 'reason', 'feed', 'reminder', 'movement', 'yorker', 'listed', 'ice', 'comparison', 'insurer', 'shoulder', 'mentally', 'kelly', 'return', 'turning', 'regime', 'certainly', 'hated', 'member', 'report', 'pres', 'mystery', 'despite', 'natural', 'removing', 'sanction', 'standing', 'blind', 'comingsoon', 'one', 'illustration', 'everyday', 'greatest', 'weed', 'fighting', 'enjoy', 'trap', 'pb', 'going', 'bleeding', 'specimen', 'prevent', 'reporting', 'premier', 'fan', 'charger', 'faced', 'suffering', 'east', 'ground', 'pulled', 'tn', 'cia', 'ashley', 'responds', 'russian', 'model', 'mount', 'include', 'thats', 'bar', 'russia', 'defect', 'stock', 'naved', 'faan', 'nope', 'angry', 'hospital', 'electronic', 'revolution', 'hollywood', 'la', 'dress', 'commit', 'haha', 'th', 'first', 'yea', 'replacing', 'trouble', 'victim', 'statement', 'hah', 'cruz', 'otrametlife', 'code', 'lol', 'shipwreck', 'inevitably', 'examiner', 'loving', 'yeah', 'pace', 'sorrow', 'energy', 'hahah', 'ended', 'day', 'used', 'antonio', 'technology', 'thought', 'rally', 'mall', 'cancelled', 'walker', 'wicked', 'like', 'oil', 'senior', 'lesbian', 'incredible', 'rate', 'thriller', 'fort', 'tsunami', 'collective', 'destroyed', 'there', 'cooler', 'least', 'degree', 'blake', 'dc', 'along', 'tha', 'player', 'move', 'bug', 'marijuana', 'military', 'physician', 'tooth', 'either', 'ontario', 'mtvhottest', 'impacted', 'hand', 'pin', 'insane', 'police', 'vaccine', 'station', 'gop', 'idk', 'buffer', 'tea', 'thee', 'missing', 'gateau', 'share', 'court', 'ago', 'donald', 'barn', 'wo', 'cruise', 'becomes', 'looked', 'prayer', 'earnings', 'apparently', 'reactor', 'nrc', 'various', 'basement', 'terrorist', 'fr', 'landing', 'minor', 'boy', 'fueling', 'survived', 'mma', 'june', 'predicted', 'ireland', 'japan', 'u', 'saturn', 'therapy', 'concert', 'front', 'feat', 'raining', 'term', 'philly', 'milkshake', 'col', 'fee', 'respond', 'collided', 'landscape', 'nyc', 'skinny', 'arm', 'produced', 'run', 'turbine', 'agree', 'lovely', 'real', 'crime', 'quite', 'emergency', 'destruction', 'wreckage', 'starving', 'mishap', 'hooligan', 'info', 'strange', 'blocked', 'use', 'jacksonville', 'prompted', 'hold', 'cost', 'library', 'sponsor', 'point', 'get', 'cuz', 'sink', 'kind', 'bowling', 'scared', 'lgbt', 'hypocrisy', 'fart', 'blizzard', 'logistics', 'tree', 'penny', 'liked', 'supposed', 'ca', 'uk', 'mistreated', 'hunk', 'survival', 'custom', 'solid', 'haram', 'bos', 'avenger', 'listen', 'announces', 'fukushima', 'history', 'awful', 'recap', 'firework', 'suicide', 'dan', 'murder', 'thx', 'bargain', 'auth', 'eat', 'k', 'plan', 'bayelsa', 'holding', 'pjnet', 'cell', 'acted', 'sandstorm', 'linkury', 'coffee', 'c4news', 'del', 'violation', 'material', 'terrorism', 'example', 'stupid', 'falcon', 'dog', 'dolphin', 'luis', 'company', 'placing', 'manager', 'hello', 'stuck', 'neighbour', 'desolation', 'uniform', 'entered', 'done', 'vest', 'download', 'critical', 'mid', 'nuclear', 'wild', 'equal', 'shift', 'lgl', 'steve', 'usually', 'smoke', 'parent', 'bang', 'sand', 'copycat', 'cite', 'changed', 'evidence', 'homosexuality', 'charity', 'bash', 'host', 'corey', 'vancouver', 'bring', 'cladding', 'trent', 'slip', 'floated', 'cable', 'add', 'sto', 'got', 'bin', 'australian', 'lost', 'athlete', 'insurance', 'ben', 'transporting', 'shooter', 'bruise', 'anthrax', 'soudelor', 'piling', 'large', 'satan', 'sex', 'bag', 'opposition', 'pick', 'cu', 'downtown', 'correction', 'closed', 'meet', 'please', 'genocide', 'nick', 'cow', 'click', 'boxer', '53inch', 'lrt', 'close', 'modi', 'type', 'ship', 'prevention', 'okay', 'legacy', 'baltimore', 'clueless', 'care', 'tomorrow', 'houston', 'blow', 'government', 'network', 'niece', 'morning', 'number', 'anti', 'drowning', 'van', 'hidden', 'seven', 'asleep', 'church', 'wowo', 'hoe', 'course', 'fire', 'expect', 'whats', 'keep', 'unknown', '30a', 'crossed', 'deliver', 'debate', 'picture', 'research', 'tired', 'canada', 'bone', 'past', 'vet', 'multiple', 'drove', 'chewing', 'chinese', '4km', 'bmw', 'robert', 'getting', 'sicily', 'alien', 'tampa', 'evacuation', 'ahh', 'planned', 'photoset', 'southampton', 'runner', 'industry', 'calamity', 'detonate', 'hard', 'causing', 'turned', 'wom', 'million', 'role', 'unlocked', 'yelling', 'pressed', 'thigh', 'wilshere', 'drill', 'stop', 'factory', 'silence', 'leg', 'month', 'root', 'stopped', 'legal', 'till', 'horse', 'evolve', 'chris', 'plug', 'tak', 'well', 'concerned', 'premium', 'laughing', '4th', 'night', 'reminds', 'yahoo', 'lorry', 'michelebachman', 'notley', 'defend', 'aunt', 'tragedy', 'telling', 'highest', 'effort', 'featured', 'bill', 'boxing', 'freak', 'elephant', 'simulate', 'jesus', 'stuff', 'soldier', 'wreck', 'evil', 'duty', 'death', 'racist', 'ghost', 'everyone', 'wd', 'catastrophic', 'sewer', 'rn', 'avalanche', 'leaf', 'planet', 'rescued', 'summer', 'playlist', 'pundit', 'soul', 'appreciated', 'troll', 'legislation', 'pretty', 'total', 'protect', 'germany', 'pre', 'jax', 'although', 'whatever', 'r', 'rea', 'toward', 'dating', 'navy', 'taylor', 'safely', 'si', 'christmas', 'incase', 'ferry', 'racing', 'discovered', 'tonto', 'king', 'poll', 'far', 'straight', 'pledge', 'odds', 'fresno', 'm4', 'olive', 'prime', 'lava', 'pray', 'unveiled', 'richmond', 'house', 'cool', 'lone', 'tied', 'live', 'dignity', 'wolf', 'language', 'beneath', 'longer', 'metro', 'allow', 'novel', 'eyewitness', 'buddy', 'safer', 'exercised', 'particularly', 'nu', 'opposite', 'pizza', 'avoid', 'leather', 'must', 'flash', 'ignition', 'swansea', 'wale', 'mistake', 'starring', 'gun', 'housing', 'late', 'pic', 'asap', 'child', 'zayn', 'torch', 'escaped', 'childhood', 'link', 'november', 'following', 'mountaineering', 'banquet', 'homeland', 'peak', 'inmate', 'authority', 'hwo', 'level', 'prepared', 'sp', 'saturday', 'harm', 'float', 'recover', 'hunter', 'temple', 'specialist', 'anchorage', 'socialism', 'assembly', 'made', 'detonation', 'selection', 'improve', 'store', 'billion', 'defense', 'unprecedented', 'em', 'city', 'slightly', 'unrest', 'floor', 'spread', 'brigade', 'helping', 'trailer', 'fishing', 'bowl', 'sewing', 'douchebag', 'profit', 'bruh', 'wan', 'automatic', 'supply', 'engineer', 'fkn', 'limit', 'biker', 'totally', 'blaze', 'fortunately', 'maria', 'm', 'ha', 'surgery', 'guy', 'mine', 'steel', 'impending', 'as', 'en', 'injures', 'senate', 'estate', 'derail', 'cafe', 'secret', 'app', 'treat', 'warship', 'elderly', 'ruined', 'begin', 'top', 'scotland', 'vantage', 'photographer', 'text', 'patient', 'nwo', 'married', 'illegal', 'beforeitsnews', 'external', 'alone', 'flood', 'mission', 'exactly', 'perquisite', 'passing', 'continues', 'caution', 'aim', 'integrity', 'socket', 'govt', 'chairman', 'maker', 'pay', 'recommend', 'reopen', 'property', 'rained', 'oth', 'expert', 'everything', 'abandoned', 'rubble', 'ur', 'audio', 'hope', 'operation', 'others', 'turn', 'upon', 'quickly', 'controlled', 'heartless', 'fate', 'match', 'salvador', 'birth', 'rid', 'yesterday', 'bernardino', 'misery', 'began', 'wondering', 'fresh', 'lady', 'commercial', 'cannon', 'thing', 'planted', 'iran', 'pakistan', 'bomber', 'quality', 'sexual', 'calgary', 'somewhere', 'give', 'dam', 'honest', 'targeting', 'nigga', 'rejected', 'totaling', 'smoking', 'flow', 'fte', 'panel', 'us', 'reality', 'selfie', 'wide', 'spill', 'khan', 'hiroshima', 'phoenix', 'criminal', 'drain', 'birthday', 'drop', 'artist', 'required', 'shake', 'loved', 'science', 'suspected', 'skin', 'dangerous', 'arrested', 'fleet', 'faulty', 'wrecked', 'ally', 'beck', 'collins', 'brave', 'wod', 'photo', 'right', 'power', 'dear', 'crashing', 'billing', 'final', 'lou', 'war', 'named', 'attacking', 'great', 'tested', 'responding', 'call', 'stab', 'ak', 'remove', 'genius', 'fourth', 'cant', 'launch', 'mlb', 'ancient', 'fix', 'stress', 'book', 'hazardous', 'sorry', 'globalwarming', 'wonder', 'banned', 'sa', 'flying', 'ant', 'life', 'med', 'greatbritishbakeoff', 'shame', 'meme', 'frank', 'gopdebate', 'inj', 'ability', 'movie', 'item', 'bagging', 'vital', 'recognize', 'pantherattack', 'box', 'hopefully', 'crowd', 'creativity', 'survive', 'student', 'happily', 'killer', 'entire', 'gift', 'fav', 'among', 'transport', 'freshman', 'freespeech', 'lamp', 'progress', 'group', 'warne', 'heat', 'gabon', 'seeing', 'performing', 'yr', 'sept', 'displaced', 'president', 'milk', 'stressful', 'truth', 'storm', 'battery', 'gordon', 'massacre', 'project', 'fury', 'window', 'dream', 'let', 'cancer', 'shaking', 'way', 'idea', 'pull', 'mate', 'paramedic', 'gunman', 'electro', 'single', 'instant', 'checked', 'freaking', 'gray', 'comment', 'classic', 'toxic', 'solar', 'architecture', 'intact', 'coverage', 'probably', 'hughes', 'cooper', 'accused', 'account', 'philadelphia', 'texas', 'hatchet', 'data', 'technique', 'scout', 'hailstorm', 'seemed', 'satellite', '30pm', 'robinson', 'warning', 'temporary', 'annual', 'recording', 'fail', 'prebreak', 'minority', 'swim', 'radio', 'physical', 'seat', 'ryan', 'gas', 'ford', 'bout', 'sake', 'radiation', 'rocky', 'seek', 'trillion', 'nowplaying', 'also', 'admits', 'theyre', 'forced', 'anonymous', 'generation', 'mike', 'israel', 'electrical', 'traffic', 'sat', 'check', 'jail', 'god', 'package', 'middle', 'owner', 'shock', 'avenue', 'franklin', 'record', 'funny', 'fucking', 'cliff', 'human', 'ny', 'strategy', 'black', 'freeway', 'protesting', 'tv', 'indie', 'clearly', 'town', 'waterway', 'boat', 'ross', 'annihilation', 'careful', 'com', 'cree', 'tennessee', 'speed', 'slanglucci', 'madinah', 'nazi', 'feminist', 'aftershock', 'coast', 'wind', 'boeing', 'bought', 'whistle', 'humaza', 'nw', 'saudi', 'kenya', 'subject', 'kanye', 'leisure', 'resistant', 'trust', 'perfect', 'themed', 'ki', 'ultimate', 'tom', 'yet', 'toronto', 'petition', 'iron', 'hey', 'tin', 'seen', 'encouragement', 'abe', 'motion', 'swimming', 'personal', 'benefit', 'picked', 'quest', 'lunch', 'farrakhan', 'possibly', 'maintain', 'involved', 'mouth', 'demand', 'largest', 'clash', 'worried', 'created', 'shadow', 'yahistorical', 'drone', 'domestic', 'friggin', 'org', 'trek', 'treeporn', 'buffalo', 'arriving', 'pussy', 'spur', 'cat', 'exacerbated', 'knee', 'escape', 'spark', 'inundation', 'cherokee', 'travel', 'tryout', 'register', 'bb4sp', 'financial', 'moving', 'starting', 'crash', 'titanic', 'wounded', 'board', 'pan', 'reshapes', 'strike', 'depressing', 'apparent', 'ban', 'cain', 'centre', 'strongly', 'hr', 'force', 'ripped', 'dropped', '5c', 'association', 'nature', 'released', 'honestly', 'lately', 'sw', 'doug', 'oh', 'concern', 'calling', 'delay', 'content', 'luck', 'mentioned', 'ooh', 'london', 'bet', 'best', 'crippling', 'wake', 'upper', 'lie', 'action', 'round', 'affect', 'neighborhood', 'seem', 'mix', 'mind', 'version', 'finding', 'settle', 'pitch', 'balance', 'year', 'civil', 'mp', 'communication', 'around', 'clown', 'defeat', 'amazon', 'many', 'driving', 'logo', 'underwater', 'wwii', 'felt', 'coal', 'mt', 'hillary', 'sentinel', 'lot', 'know', 'yes', 'involving', 'relief', 'priority', 'thousand', 'fluid', 'nursing', 'bath', 'suit', 'certificate', 'amazing', 'x', 'injury', 'mhtw4fnet', 'islamic', 'beam', 'negro', 'headed', 'idiot', 'bore', 'yo', 'break', '5th', 'log', 'steal', 'lizard', 'trial', 'saved', 'lethal', 'alternative', 'contain', 'famine', 'pharaoh', 'paris', 'bitch', 'declares', 'sound', 'safety', 'apollo', 'none', 'elite', 'charlotte', 'summertime', 'entrepreneur', 'na', 'value', 'word', 'catastrophe', 'rest', 'gallipoli', 'exposed', 'ride', 'combo', 'dorman', '3g', 'wit', 'ranking', 'lived', 'gf', 'drug', 'panicking', 'landslide', 'electricity', 'served', 'nothing', 'prince', 'biggest', 'pack', 'forgive', 'obliterated', 'tool', 'struggling', 'outdoor', 'humanconsumption', 'rolling', 'omar', 'noonan', 'xd', 'reported', 'face', 'memphis', 'hasbro', 'grill', 'allows', 'walter', 'accidentally', 'dame', 'cloud', 'drake', 'certain', 'al', 'client', 'fennovoima', 'kraft', 'trend', 'intensity', 'electric', 'glass', 'green', 'requiring', 'stranded', 'look', 'census', 'rear', 'charlie', 'pump', 'sea', 'faux', 'civilization', 'italy', 'knob', 'play', 'come', 'mom', 'demonstration', 'undergroundrailraod', 'collection', 'due', 'roll', 'hotel', 'accident', 'dark', '3rd', 'arnley', 'rotation', 'wearing', 'rightways', 'transit', 'averted', 'small', 'attempt', 'belongs', 'blowing', 'genuine', 'butt', 'say', 'removed', 'condo', 'lightning', 'apply', 'weapon', 'agreed', 'interesting', 'founder', 'ptsdchat', 'larger', 'anymore', 'scandal', 'side', 'minister', 'temperature', 'training', 'outage', 'moore', 'mum', 'afghan', 'confirmed', 'yellow', 'signed', 'planning', 'bullet', 'distinct', 'surrounded', 'scare', 'national', 'cheese', 'age', 'dakota', 'weak', 'looting', 'henry', 'spaniel', 'queen', 'cab', 'hearing', 'interlaken', 'punishment', 'onlinecommunities', 'race', 'faroeislands', 'flew', 'see', 'debt', 'drag', 'image', 'forbes', 'wed', 'nc', 'die', 'residential', 'surely', 'grand', 'ted', 'fact', 'sense', 'formed', 'gem', 'emotion', 'active', 'reduce', 'deserves', 'killed', 'blanket', 'standard', 'cnn', 'expand', 'vehicle', 'jealous', 'april', 'snack', 'men', 'angeles', 'fox', 'mr', 'three', 'eu', 'miss', 'warrior', 'iraqi', 'icymi', 'room', 'responsible', 'aba', 'department', 'pile', 'boston', 'north', 'caught', 'shirt', 'volcano', 'bank', 'bot', 'question', 'battling', 'er', 'loading', '429cj', 'control', 'anxious', 'excuse', 'fixed', '5pm', 'fbi', 'explode', 'teaching', 'finger', 'common', 'cheap', 'latest', 'film', 'york', 'blocking', 'saying', 'thick', 'led', 'possibility', 'longs', 'shop', 'winter', 'referring', 'cop', 'december', 'sneak', 'wud', 'elizabeth', 'third', 'screaming', 'demolish', 'range', 'hazard', 'core', 'general', 'malaysia', 'iphone', 'motor', 'ay', 'pol', 'albany', 'lighting', 'joining', 'jackson', 'obviously', 'nineoneone', 'lion', 'avoided', 'heroine', 'field', 'journalist', 'gm', 'rock', 'completed', 'donate', 'connector', 'southdowns', 'document', 'co', 'testing', 'youtube', 'riot', 'hill', 'away', 'known', 'austin', 'hiphop', 'n', 'lane', 'snd', 'lab', 'lasting', 'episode', 'post', 'except', 'deal', 'disappearance', 'obliterate', 'solution', 'anger', 'bombed', 'aussie', 'sarah', 'breakingnews', 'guess', 'absolutely', 'syndrome', 'recall', 'trace', 'investigating', 'bell', 'replace', 'yay', 'violent', 'series', 'political', 'watched', 'people', 'cash', 'heavy', 'emotionally', 'earlier', 'jenner', 'time', 'bless', 'oops', 'john', 'antioch', 'professional', 'fm', 'el', 'internally', 'buy', 'threat', 'waste', 'ev', 'penalty', 'dante', 'dreaming', 'bg', 'news', 'understand', 'multi', 'exp', 'chernobyl', 'recycling', 'especially', 'twister', 'zombie', 'recorded', 'reject', 'brown', 'grenade', 'costly', 'every', 'furious', 'veteran', 'ton', 'making', 'line', 'barely', 'bloomberg', 'flooding', 'thank', 'wood', 'paul', 'true', 'brazil', 'plate', 'rly', 'dy', 'together', 'ruin', 'worker', 'space', 'willing', 'dying', 'home', 'wealth', 'became', 'rob', 'french', 'adult', 'browser', 'blazing', 'private', 'chose', 'time2015', 'walk', 'detail', '7a', 'catching', 'depth', 'evacuate', 'mark', 'bathroom', 'refugee', 'undercover', 'brief', 'blvd', 'snap', 'college', 'p', 'twice', 'scifi', 'ocean', 'squad', 'remains', 'tokyo', 'aircraft', 'gambit', 'plague', 'cargo', 'agent', 'dryer', 'fatal', 'senator', 'affecting', 'transfer', 'fierce', 'bully', 'jon', 'trfc', 'never', 'claim', 'senso', 'cont', 'backpack', 'insight', 'bringing', 'virus', 'prone', 'belief', 'france', 'tattoo', 'any1', 'sf', 'go', 'abused', 'euro', 'cindy', 'sponge', 'happened', 'ibooklove', 'ch4', 'worst', 'attack', 'consequence', 'brisk', 'garbage', 'greeting', 'enugu', 'transformation', 'cigarette', 'begging', 'ego', 'throwing', 'victoria', 'california', 'security', 'mud', 'computer', 'swell', 'chief', 'eight', 'sister', 'torso', 'hobo', 'water', 'international', 'meter', 'missile', 'eye', 'system', 'heavenly', 'southeast', 'parade', 'environment', 'historic', 'bc', 'something', 'airplane', 'blown', 'loss', 'cyber', 'fighter', 'institute', 'knoxville', 'plummeted', 'etc', 'rainier', 'according', 'environmental', 'failure', 'busy', 'brain', 'theory', 'rape', 'restore', 'make', 'occurs', 'expose', 'schedule', 'hostage', 'recipe', 'curfew', 'dad', 'awesome', 'wa', 'brooklyn', 'option', 'style', 'feel', 'rank', 'crack', 'dry', 'rose', 'server', 'imported', 'reading', 'jumper', 'walmart', 'kingdom', 'red', 'glenn', 'original', 'mourns', 'atm', 'patience', 'sweet', 'thanks', 'budget', 'job', 'played', 'happen', 'management', 'law', 'denier', 'tale', 'jewish', 'lead', 'christian', 'ethiopian', 'literally', 'talkin', 'recovery', 'jazz', 'cleared', 'forest', 'legendary', 'capture', 'pathogen', 'billboard', 'oral', 'quarantined', 'independent', 'beautiful', 'society', 'searching', 'compliant', 'shouting', 'alert', 'center', 'swarm', 'denali', 'take', 'tidal', 'holland', 'suv', 'collapsed', 'irandeal', 'robot', 'walking', 'knowing', 'incredibly', 'fam', 'feeling', 'dance', 'rip', 'a1', 'gaining', 'liberal', 'dinner', 'didnt', 'ptsd', 'camper', 'peace', 'f', 'gander', 'batter', 'vinyl', 'across', 'though', 'nightmare', 'suddenly', 'dr', 'recommended', 'recently', 'sassy', 'noise', 'superhero', 'karma', 'deadly', 'aoms', 'hour', 'homeless', 'anniversary', 'internet', 'attacked', 'goal', 'today', 'loses', 'reveals', 'yall', 'clinton', 'coastal', 'love', 'wall', 'olympic', 'worked', 'tension', 'trunk', 'grace', 'australia', 'price', 'christ', 'collision', 'army', 'h', 'average', 'formation', 'toilet', 'chocolate', 'calm', 'ash', 'fireman', 'fled', 'pit', 'palin', 'e', 'fossil', 'mountain', 'weird', 'arrive', 'crisis', 'female', 'supreme', 'welfare', 'exit', 'exist', 'mad', 'blessing', 'ima', 'machine', 'venezuela', 'friday', 'died', 'nd', 'accept', 'opinion', 'homeowner', 'auspol', 'trip', 'treasure', 'flip', 'gr', 'apocalypse', 'sr', 'salem', 'fruit', 'seriously', 'effect', 'kidnap', 'brother', 'dublin', 'omg', 'invest', 'stealing', 'md', 'sleeping', 'bedroom', 'bed', 'artificial', 'reid', 'ripple', 'near', 'half', 'season', 'fat', 'watching', 'actually', 'ave', 'step', 'struck', 'zippednews', 'possible', '4x4', 'forget', 'pool', 'fashionable', 'salt', 'charles', 'impact', 'adding', 'applies', 'everywhere', 'soon', 'vegetarian', 'anyone', 'protest', 'self', 'chronicle', 'quran', 'mass', 'irony', 'necessary', 'approval', 'director', 'nation', 'ahead', 'loop', 'official', 'site', 'appears', 'friend', 'ft', 'journalism', 'tech', 'rare', 'cecilthelion', 'hampshire', 'repair', 'currently', 'soviet', 'iraq', 'chill', 'locke', 'page', 'caused', 'iranian', 'mariah', 'pbban', 'stephen', 'huge', 'slower', 'ex', 'ball', 'platform', 'colour', 'afterlife', 'washington', 'flight', 'union', 'glorious', 'mega', 'nude', 'sub', 'drinking', 'heading', 'threw', 'vacation', 'talent', 'sad', 'amirite', '2pm', 'quiz', 'business', 'find', 'damaged', 'openly', 'body', 'pilot', 'mean', 'precious', 'press', 'sm', 'somehow', 'crew', 'fine', 'rescue', 'vulnerable', 'reopening', 'tremor', 'source', 'hoping', 'japanese', 'beginner', 'ink', 'iii', 'bal', 'san', 'daniel', 'fly', 'esteemed', 'theatre', 'dust', 'shit', 'slowly', 'outside', 'snowball', 'twia', 'shape', 'troy', 'fallen', 'asia', 'scott', 'southern', 'blame', 'rep', 'summit', 'could', 'snowstorm', 'maintenance', 'estimate', 'voter', 'valley', 'hundred', 'rss', 'nice', 'realized', 'driven', 'demon', 'derailed', 'focus', 'trinity', 'denial', 'rule', 'album', 'desolate', 'reach', 'crystal', 'realise', 'exterminate', 'warned', 'tweet', 'mgm', 'grew', 'lake', 'combined', 'game', 'band', 'tablet', 'ml', 'nestleindia', 'reshape', 'fear', 'review', 'bombing', 'bioterror', 'chase', 'firetruck', 'europe', 'publicizing', 'second', 'angel', 'acquire', 'slow', 'clock', 'row', 'joint', 'google', 'allowed', 'last', 'magic', 'kendall', 'electrocute', 'traditional', 'open', 'los', 'airport', 'upheaval', 'path', 'passenger', '360wisenews', 'forbid', 'democracy', 'dramatic', 'julian', 'couple', 'murderous', 'sight', 'cast', 'commerce', 'outlook', 'beach', 'destroy', 'fast', 'surface', 'salmon', 'kiev', 'lawton', 'driver', 'thu', 'spectacular', 'til', '5', 'purchased', 'faceless', 'everytime', 'flag', 'shower', 'corp', 'someone', 'im', 'issue', 'watch', 'westeros', 'clear', '1st', 'thunderstorm', 'wildhorses', 'indian', 'pretend', 'rt', 'strong', 'tahoe', 'chance', 'tank', 'murderer', 'test', 'disgusting', 'b4', 'gotten', 'choking', 'sparked', 'started', 'relationship', 'local', 'allah', 'dude', 'immediately', 'drive', 'throughout', 'hero', 'scary', 'sun', 'coral', 'legion', 'without', 'challenged', 'af', 'card', 'broken', 'torching', 'sized', 'mercy', 'article', 'probe', 'engine', 'purse', 'mutant', 'lmfao', 'six', 'scale', 'india', 'widespread', 'west', 'running', 'cyclone', 'nearly', 'occurred', 'able', 'cross', 'favorite', 'tribune', 'dancer', 'programme', 'note', 'hoped', 'greenway', 'speaking', 'whether', 'encounter', 'museum', 'fedex', 'mention', 'chair', 'silent', 'prepare', 'peep', 'leave', 'read', 'weighs', 'split', 'blast', 'reportedly', 'miner', 'matter', 'africa', 'leader', 'family', 'drunk', 'follower', 'moved', 'dollar', 'cave', 'delta', 'careless', 'devastation', '1m', 'thursday', 'amid', 'hunt', 'label', 'shooting', 'base', 'not', 'cup', 'user', 'worse', 'eventually', 'art', 'land', 'health', 'temptation', 'place', 'wanted', 'wildfire', 'cry', 'w', 'show', 'would', 'deluged', 'golf', 'nowhere', 'kerricktrial', 'phone', 'reunion', 'whoa', 'hat', 'usatoday', 'sensor', 'smoky', 'smaug', 'shell', 'train', 'cobra', 'flattened', 'slide', 'au', 'epilepsy', 'utterly', 'santa', 'messi', 'service', 'johnson', 'dead', 'cabin', 'knife', 'hiring', 'staff', 'conflict', 'area', 'rubber', 'predict', 'trump', 'view', 'sismo', 'hot', 'declined', 'simple', 'former', 'lord', 'heard', 'hurry', 'may', 'guest', 'whipped', 'comedy', 'took', 'good', 'nema', 'yep', 'send', 'pandemonium', 'usgs', 'newsintweets', 'wedding', 'dumb', 'pamela', 'siren', 'told', 'light', 'fight', 'track', 'notexplained', 'politics', 'hood', 'ebola', 'kill', 'tornado', 'syrian', 'target', 'reinstate', 'starter', 'horizon', 'organization', 'actual', 'chick', 'belly', 'congress', 'since', 'shipping', 'based', 'patriot', 'cook', 'corner', 'esh', 'ok', 'looking', 'mod', 'sounding', 'knew', 'treatment', 'leak', 'newest', 'native', 'cbc', 'backyard', 'detroit', 'youth', 'piece', 'try', 'min', 'dare', 'prophet', 'bridge', 'gon', 'apc', 'guide', 'african', 'damn', 'camp', 'plus', 'tear', 'release', 'collapse', '10th', 'county', 'learn', 'bigger', 'market', 'joe', 'v', 'da', 'putin', 'panic', 'pls', 'spit', 'asian', 'ian', 'team', 'low', 'rat', 'rather', 'godslove', 'need', 'jack', 'humble', 'prompt', 'clean', 'gunsense', 'wire', 'vanuatu', 'bigamist', 'girl', 'ask', 'background', 'reduced', 'plane', 'continue', 'asked', 'response', 'cut', 'minion', 'work', 'prefer', 'blog', 'meal', 'eaten', 'afraid', 'soft', 'knight', 'offer', 'happens', 'brutally', 'crashed', 'votejkt48id', 'dm', 'bee', 'bit', 'earth', 'royal', 'earthquake', 'engulfed', 'tell', 'fun', 'always', 'current', 'hole', 'administration', 'blacklivesmatter', 'hell', 'within', 'parking', 'puncture', 'telegraph', 'olap', 'acting', 'verdict', 'activated', 'morgan', 'less', 'cold', 'ah', 'mf', 'brought', 'set', 'understanding', 'affected', 'pak', 'master', 'jeff', 'whole', 'premiere', 'reflect', 'cancel', 'behalf', 'attitude', 'indeed', 'aka', 'hijacking', 'wipp', 'warn', 'previous', 'ornament', 'devastated', 'opened', 'hamburg', 'demolished', 'address', 'main', 'hit', 'birmingham', 'utter', 'heart', 'ppl', 'deny', 'trauma', 'aid', 'disaster', 'arson', 'rush', 'rifle', 'shutdown', 'stand', 'battle', 'prophetmuhammad', 'discussion', 'wednesday', 'notice', 'tiger', 'silver', 'hate', 'nato', 'aust', 'targeted', 'ever', 'medium', 'bake', 'bottom', 'pickup', 'gmt', 'sends', 'suppose', 'michael', 'mental', 'tunein', 'lock', 'lmfaoooo', 'damage', 'kca', 'plaguing', 'bare', 'l', 'william', 'club', 'population', 'mayhem', 'fall', 'vladimir', 'camping', 'surprised', 'allegiance', 'assistant', 'atomic', 'ap', 'joke', 'whirlwind', 'money', 'ran', 'brewing', 'biological', 'challenge', 'ablaze', 'razed', 'acid', 'tanzania', 'non', 'cement', 'val', 'un', 'myfitnesspal', 'tbt', 'parenthood', 'superstition', 'drink', 'sydney', 'cord', 'animal', 'tough', 'warns', 'bother', 'crown', 'meltdown', 'btw', 'argument', 'oppression', 'somalia', 'blood', 'snow', 'realize', 'lightening', 'build', 'story', 'remain', 'stay', 'inspiring', 'start', 'gov', 'dutch', 'coat', 'flame', 'even', 'invited', 'hair', 'vine', 'gif', 'chile', 'unnecessary', 'result', 'voice', 'illusion', 'kerry', 'massive', 'survey', 'posted', 'updated', 'atlantic', '6th', 'battlefield', 'abortion', 'tape', 'bound', 'enormous', 'error', 'election', 'mineral', 'ten', 'happiness', 'explosion', 'graveyard', 'considering', 'phantom', 'voting', 'aa', 'fund', 'resulting', 'hosting', 'fatality', 'roof', 'mohammed', 'prison', 'grow', 'doc', 'throat', 'mail', 'fucked', 'associated', 'ready', 'full', 'emerges', 'acc', 'customer', 'fuck', 'woman', 'ending', 'request', 'annihilated', 'bummer', 'vision', 'wait', 'triggered', 'timeline', 'specific', 'potential', 'ik', 'horrible', 'fashion', 'marine', 'offers2go', 'information', 'winston', 'direction', 'fraction', 'lung', 'future', 'mac', 'scar', 'survivor', 'activity', 'letting', 'brings', '10pm', 'situation', 'promise', 'township', 'breaking', 'cage', 'lifted', 'melt', 'stretcher', 'foodscare', 'democrat', 'pm', 'harper', 'gt', 'inundated', 'act', 'pdp', 'restaurant', 'pas', 'already', '300w', 'leo', 'asking', 'list', 'hunger', 'tune', 'jet', 'niagara', 'hellfire', 'date', 'tax', 'monitor', 'enemy', 'forgot', 'defendant', 'english', 'poverty', 'extensive', 'anybody', 'ridiculous', 'hatred', 'answer', 'taco', 'italian', 'jailed', 'elliott', 'bunch', 'shocked', 'online', 'pedestrian', 'downfall', 'gang', 'george', 'breakfast', 'mexico', 'upgraded', 'tho', 'gone', 'pirate', 'win', 'flush', 'stadium', 'social', 'newlywed', 'cause', 'exploration', 'smart', 'united', 'atlanta', 'turkish', 'catch', 'inferno', 'monday', 'wayne', 'hint', 'alive', 'peaceful', 'spring', 'else', 'study', 'extra', 'ig', 'cycling', 'believe', 'bite', 'advance', 'table', 'ferguson', 'blowout', 'studio', 'chart', 'needed', 'fell', 'gunshot', 'proceeds', 'cnbc', 'section', 'via', 'revealed', 'kept', 'name', 'arena', 'component', 'music', 'remember', 'gold', 'admin', 'reward', 'writer', 'better', 'wrong', 'vessel', 'moral', 'community', 'double', 'colorado', 'grief', 'quote', 'exclusive', 'serious', 'helicopter', 'emmerdale', 'bro', 'apocalyptic', 'towards', 'period', 'gary', 'arsenal', 'mph', 'cameroon', 'georgia', 'gps', 'poor', 'modified', 'smh', 'islam', 'put', 'flower', 'tab', 'unit', 'experienced', 'remembering', 'broke', 'building', 'autoinsurance', 'avoiding', 'injured', 'hurt', 'search', 'father', 'brick', 'shanghai', 'mourning', 'amageddon', 'excellent', 'expected', 'nugget', 'ghostwriter', 'lower', 'talk', 'tory', 'sell', 'pain', 'condition', 'exploded', 'orange', 'fit', 'spot', 'danger', 'providence', 'mining', 'street', 'sky', 'bush', 'instead', 'knock', 'donation', 'important', 'perhaps', 'womens', 'gave', 'loose', 'star', 'teacher', 'pipe', 'farm', 'jonathanferrell', 'unto', 'called', 'country', 'addict', 'tide', 'rickperry', 'thin', 'medical', 'sort', 'unavoidable', 'richard', 'deep', 'meeting', 'change', 'maybe', 'league', 'nine', 'wish', 'device', 'dat', 'saving', 'screamed', 'alaska', 'designed', 'usual', 'cutting', 'sketch', 'multidimensi', 'wheel', 'loud', 'jp', 'memorial', 'worry', 'appointment', 'sleep', 'daily', 'casualty', 'abandon', 'rating', 'oklahoma', 'jan', 'existence', 'faster', 'campaign', 'otherwise', 'cr', 'demi', 'hd', 'maj', 'con', 'serial', 'extreme', 'tote', 'mmmmmm', 'neil', 'directioners', 'think', 'ed', 'desire', 'bn', 'se', 'public', 'hear', 'scream', 'applaud', 'troop', 'dental', 'fuel', 'managed', 'po', 'cd', 'mo', 'bioterrorism', 'kicked', 'mercury', 'percent', 'rising', 'gilbert23', 'teen', 'arrived', 'psychiatric', 'ram', 'charged', 'safe', 'program', 'seems', 'whale', 'event', 'oak', 'poplar', 'sign', 'forgiven', 'pregnant', 'hike', 'inside', 'infamous', 'western', 'european', 'punch', 'firefighter', 'tour', 'jedi', 'scwx', 'august', 'england', 'rioting', 'destiny', 'responder', 'besides', 'prez', 'suck', 'bomb', 'daughter', 'writing', 'burnt', 'shocking', 'much', 'gn', 'happy', 'bull', 'drowned', 'unconfirmed', 'covered', 'spider', 'dem', 'buddha', 'rail', 'funtenna', 'extender', 'de', 'tuesday', 'bicep', 'torture', 'nigerian', 'beyond', 'mile', 'killing', 'state', 'fully', 'long', 'beginning', 'korea', 'location', 'head', 'car', 'behind', 'vote', 'firey', 'person', 'sure', 'random', 'tcot', 'potus', 'drought', 'loretta', 'kiss', 'helen', 'left', 'score', 'ri', 'song', 'sit', 'bump', 'exam', 'party', 'part', 'registered', 'beer', 'tuned', 'support', 'terrifying', 'special', 'sunk', 'learned', 'ron', 'july', 'dijk', 'memory', 'growth', 'dw', 'rome', 'wow', 'born', 'fair', 'oooh', 'gi', 'tracking', 'order', 'visit', 'four', 'terror', 'neighbor', 'quarantine', 'shoe', 'surah', 'fez', 'civilian', 'cad', 'palm', 'wash', 'absolute', 'langley', 'sideline', 'mississauga', 'kinda', 'finally', 'raised', 'fence', 'facing', 'sunday', 'philippine', 'crazy', 'short', 'completely', 'foster', 'strip', 'campfire', 'burn', 'chicago', 'federal', 'officially', 'sterling', 'installation', 'showed', 'suspect', 'nearby', 'failed', 'risk', 'trafford', 'armageddon', 'crater', 'isi', 'kick', 'holmgren', 'weather', 'thomas', 'ar', 'bundled', 'dubstep', 'mode', 'arsonist', 'jam', 'beat', 'mets', 'gain', 'justice', 'journey', 'speak', '2pcs', 'hybrid', 'email', 'tonight', 'frog', 'attention', 'internal', 'follows', 'tyre', 'fold', 'upset', 'vegetable', 'hijacker', 'freedom', 'tutor', 'jean', 'specially', 'oooooohhhh', 'license', 'seattle', 'id', 'proud', 'spinning', 'interview', 'unlocking', 'ambulance', 'ga', 'medieval', 'returned', 'humanity', 'ta', 'sir', 'island', 'message', 'refund', 'michigan', 'purple', 'minute', 'taking', 'quoted', 'sinking', 'found', 'followback', 'chevrolet', 'dock', 'world', 'monitoring', 'rise', 'jonathan', '1a', 'burst', 'parole', 'anything', 'enjoying', 'blue', 'problem', 'wy', 'strategicpatience', 'structure', 'american', 'food', 'cricket', 'trying', 'beard', 'grown', 'investigation', 'epic', 'disruptive', 'betrayed', 'related', 'thinking', 'battleship', 'bear', 'photography', 'caribbean', 'nobody', 'using', 'striking', 'china', 'conquest', 'ignored', 'vip', 'end', 'global', 'comp', 'enhanced', 'delivers', 'nah', 'apple', 'rd', 'era', 'sick', 'ill', 'stewart', 'hijack', 'bike', 'spirit', 'thrown', 'zone', 'context', 'forecast', 'reagan', 'thunder', 'weekend', 'lil', 'football', 'vietnamese', 'imagine', 'react', 'governor', 'cover', 'worth', 'solitude', 'next', 'controller', 'burning', 'fake', 'trophy', 'personnel', 'va', 'air', 'vega', 'b', 'adventure', 'twitter', 'escaping', 'refuse', 'road', 'shut', 'likely', 'constant', 'crap', 'almost', 'definitely', 'respect', 'coming', 'profile', 'footage', 'continued', 'prepper', 'ovo', 'distributed', 'block', 'pdx911', 'florida', 'witness', 'nail', 'obliteration', 'st', 'kit', 'monster', 'roster', 'evacuated', 'hi', 'fifth', 'famous', 'meek', 'retweet', 'dealing', 'picking', 'familia', 'j', 'class', 'came', 'dont', 'wave', 'deluge', 'aug', 'gay', 'interest', 'autobiography', 'tube', 'stepped', 'present', 'bp', 'simulation', 'honor', 'offensive', 'grove', 'vods', 'meant', 'ii', 'smell', 'op', 'festival', 'crush', 'stir', 'bay', 'mullah', 'realtime', 'super', 'negative', 'wont', 'badge', 'headline', '15th', 'pulling', 'route', 'powerful', 'tried', 'bbc', 'chest', 'dutton', 'park', 'letter', 'including', 'mobile', 'denver', 'digit', 'early', 'frontpage', 'swallowed', 'bounty', 'gmmbc', 'structural', 'tie', 'cyclist', 'sinkhole', 'case', 'method', 'passed', 'backup', 'setting', 'false', 'fool', 'odeon', 'alabama', 'jamaica', 'talking', 'gbbo', 'liberty', 'sweat', 'deed', 'spoke', 'two', 'credit', 'breathing', 'enough', 'thanku', 'ceo', 'solve', 'taken', 'playing', 'five', 'pp', '2nd', 'fragile', 'said', 'sunset', 'want', 'pro', 'hysteria', 'forgotten', 'charge', 'wi', 'announcement', 'tip', 'wtf', 'spent', 'bloody', 'terrible', 'save', 'proof', 'bird', 'victory', 'procedure', 'new', 'truck', 'connection', 'sooo', 'worstsummerjob', 'meat', 'sitting', 'greg', 'endangered', 'campus', 'scene', 'bad', 'boot', 'major', 'ray', 'abuse', 'sport', 'underway', 'school', 'dragon', 'auto', 'rain', 'fired', 'pam', 'muslim', 'treating', 'emotional', 'confirm', 'innocent', 'halifax', 'crushed', 'portion', 'ep', 'practice', 'droid', 'design', 'engage', 'hipster', 'afghanistan', 'still', 'demolition', 'adoption', 'lesson', 'drum', 'wound', 'empty', 'plant', 'mock', 'swept', 'obama', 'inspection', 'week', 'policy', 'jordan', 'blew', 'sometimes', 'repatriated', 'leaving', 'patch', 'neck', 'saw', 'hoax', 'windy', 'dorret', 'rocket', 'scientist', 'logic', 'trapped', 'kid', 'increased', 'drawn', '80', 'counter', 'held', 'drifting', 'tribal', 'destroying', 'extends', 'follow', 'highway', 'sue', 'sep', 'sample', 'dvd', 'unsafe', 'german', 'living', 'fettilootch', 'woke', 'normal', 'offroad', 'wrap', 'kitten', 'bicycle', 'old', 'legit', 'horror', 'border', 'pressure', 'incident', 'nuke', 'ohio', 'man', 'curved', 'mess', 'netanyahu', 'reddit', 'invoice', 'omfg', 'high', 'metal', 'apartment', 'xp', 'individual', 'drool', 'sixth', 'rider', 'mania', 'idp', 'wmata', 'boundary', 'diego', 'consider', 'lying', 'quarter', 'calorie', 'might', 'added', 'blight', 'raider', 'help', 'foot', 'wb', 'decide', 'climate', 'alarm', 'headquarters', 'september', 'sunni', 'glad', 'cake', 'factor', 'shoot', 'pounded', 'assistance', 'bookboost', 'university', 'doctor', 'older', 'different', 'size', 'per', 'virgil', 'white', 'radar', 'republican', 'moulding', 'paper', 'touched', 'detained', 'another', 'amongst', 'ee', 'ear', 'subreddits', 'worldnews', 'hitting', 'electrocuted', 'equipment', 'laden', 'extremely', 'description', 'magnitude', 'accuses', 'truly', 'ty', 'officer', 'minded', 'cue', 'violence', 'scheme', 'hungry', 'waiting', 'expensive', 'create', 'twin', 'south', 'leading', 'sanctioned', '4wd', 'rescuer', 'handbag', 'blamed', 'toe', 'spain', 'disease', 'opera', 'falling', 'forever', 'linked', 'david', 'office', 'conference', 'coworker', 'tent', 'update', 'talkradio', 'grass', 'stream', 'magginoodle', 'buried', 'partnership', 'become', 'saint', 'mill', 'ebay', 'cousin', 'windstorm', 'young', 'diamond', 'mudslide', 'closing', 'went', 'object', 'traveling', 'settlement', 'chemical', 'surfer', 'son', 'free', 'portland', 'plot', 'happening', 'stolen', 'often', 'seismic', 'holy', 'katrina', 'circle', 'charging', 'carry', 'working', 'exchange', 'later', 'heartbreak', 'attained', 'losing', 'mayan', 'geyser', 'ab', 'horn', 'jacket', 'humidity', 'mole', 'mechanical', 'thru', 'mini', 'garden', 'coyote', 'moment', 'carried', 'collide', 'investing', 'ferrell', 'burned', 'baby', 'pepper'}\n",
            "Top 10 bigramas disaster: [(('suicide', 'bomber'), 60), (('northern', 'california'), 41), (('oil', 'spill'), 38), (('burning', 'building'), 36), (('suicide', 'bombing'), 35), (('california', 'wildfire'), 35), (('bomber', 'detonated'), 30), (('confirmed', 'mh370'), 29), (('year', 'old'), 29), (('home', 'razed'), 29)]\n",
            "Top 10 bigramas non-disaster: [(('body', 'bag'), 49), (('cross', 'body'), 39), (('liked', 'video'), 34), (('look', 'like'), 32), (('gon', 'na'), 32), (('wan', 'na'), 30), (('full', 'read'), 28), (('feel', 'like'), 25), (('body', 'bagging'), 24), (('burning', 'building'), 23)]\n",
            "Top 10 trigramas disaster: [(('suicide', 'bomber', 'detonated'), 30), (('northern', 'california', 'wildfire'), 29), (('latest', 'home', 'razed'), 28), (('home', 'razed', 'northern'), 28), (('pkk', 'suicide', 'bomber'), 28), (('bomber', 'detonated', 'bomb'), 28), (('razed', 'northern', 'california'), 27), (('16yr', 'old', 'pkk'), 27), (('old', 'pkk', 'suicide'), 27), (('family', 'sue', 'legionnaire'), 26)]\n",
            "Top 10 trigramas non-disaster: [(('cross', 'body', 'bag'), 24), (('reddit', 'quarantine', 'offensive'), 21), (('quarantine', 'offensive', 'content'), 20), (('pick', 'fan', 'army'), 17), (('reddit', 'new', 'content'), 16), (('new', 'content', 'policy'), 16), (('china', 'stock', 'market'), 16), (('stock', 'market', 'crash'), 16), (('full', 'read', 'ebay'), 15), (('ignition', 'knock', 'detonation'), 15)]\n",
            "\n",
            "=== MÉTRICAS (Validación) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8058    0.9022    0.8512       869\n",
            "           1     0.8455    0.7110    0.7724       654\n",
            "\n",
            "    accuracy                         0.8201      1523\n",
            "   macro avg     0.8256    0.8066    0.8118      1523\n",
            "weighted avg     0.8228    0.8201    0.8174      1523\n",
            "\n",
            "\n",
            "=== ERRORES DE EJEMPLO ===\n",
            "\n",
            "True=0 Pred=1\n",
            "step one get mass murderer portrait yuan\n",
            "\n",
            "True=1 Pred=0\n",
            "hollywood movie trapped miner released chile hollywood movie trapped miner starring\n",
            "\n",
            "True=1 Pred=0\n",
            "thu aug gmt utc millcityio theramin siren\n",
            "\n",
            "True=1 Pred=0\n",
            "drown demon know swim\n",
            "\n",
            "True=1 Pred=0\n",
            "need plant pacific cyclone season would help\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# LAB 5 - Minería de Textos y Análisis de Sentimiento\n",
        "# Script integral con:\n",
        "#   Parte 1: Snapshot del dataset\n",
        "#   Parte 2: Preprocesamiento (conservar palabra de hashtag, tratar \"911\", lematización)\n",
        "#   Parte 3: Unigramas por clase + WordCloud + Top-10 barras\n",
        "#   Parte 4: Bigramas y Trigramas por clase\n",
        "#   Parte 5: Modelo preliminar (TF-IDF 1-2-gramas + Regresión Logística)\n",
        "# Produce: CSVs, PNGs y prints de métricas en consola\n",
        "# ==============================================================\n",
        "\n",
        "# -----------------------\n",
        "# 0) IMPORTS Y CONFIG\n",
        "# -----------------------\n",
        "import os\n",
        "import re\n",
        "import html\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# SKLEARN (Modelo preliminar)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# --- Descargas NLTK robustas según la versión instalada ---\n",
        "import nltk\n",
        "from nltk.data import find\n",
        "\n",
        "def ensure_nltk(resource, quiet=True):\n",
        "    try:\n",
        "        find(resource)\n",
        "    except LookupError:\n",
        "        # map a resource path to its download key\n",
        "        key = resource.split(\"/\", 1)[-1].split(\"/\")[0]  # e.g., \"punkt\" or \"punkt_tab\"\n",
        "        nltk.download(key, quiet=quiet)\n",
        "\n",
        "# Tokenizers\n",
        "ensure_nltk('tokenizers/punkt')\n",
        "# Algunas versiones nuevas de NLTK requieren también 'punkt_tab'\n",
        "try:\n",
        "    ensure_nltk('tokenizers/punkt_tab')\n",
        "except Exception:\n",
        "    pass  # en versiones viejas no existe; ignorar\n",
        "\n",
        "# Stopwords, WordNet y OMW\n",
        "ensure_nltk('corpora/stopwords')\n",
        "ensure_nltk('corpora/wordnet')\n",
        "ensure_nltk('corpora/omw-1.4')\n",
        "\n",
        "\n",
        "# Asegurar descargas necesarias de NLTK\n",
        "nltk.download('punkt', quiet=True)\n",
        "# NOTA: No usar 'punkt_tab'\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# Carpeta de salida\n",
        "OUT_DIR = \"outputs_lab5\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) CARGA DE DATOS + SNAPSHOT (PARTE 1)\n",
        "#    - Dimensiones, nulos, distribución de target, muestra\n",
        "# ------------------------------------------------------------\n",
        "def snapshot_dataset(df: pd.DataFrame, out_dir: str = OUT_DIR) -> None:\n",
        "    \"\"\"Imprime y guarda un resumen rápido del dataset.\"\"\"\n",
        "    print(\"\\n=== SNAPSHOT DEL DATASET ===\")\n",
        "    print(\"Dimensiones:\", df.shape, \"\\n\")\n",
        "\n",
        "    nulls = (df.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
        "    print(\"Nulos por columna (%):\\n\", nulls, \"\\n\")\n",
        "\n",
        "    if 'target' in df.columns:\n",
        "        print(\"Distribución de target (conteo):\\n\", df['target'].value_counts(dropna=False), \"\\n\")\n",
        "        print(\"Distribución de target (%):\\n\", (df['target'].value_counts(normalize=True) * 100).round(2), \"\\n\")\n",
        "    else:\n",
        "        print(\"⚠️ Columna 'target' no encontrada. Se omitirá su distribución.\\n\")\n",
        "\n",
        "    sample_cols = [c for c in ['id', 'keyword', 'location', 'text', 'target'] if c in df.columns]\n",
        "    sample_df = df[sample_cols].sample(min(5, len(df)), random_state=42)\n",
        "    print(\"Muestra de filas (5 o menos):\\n\", sample_df, \"\\n\")\n",
        "\n",
        "    # Guardar snapshot a disco\n",
        "    nulls.to_csv(os.path.join(out_dir, \"snapshot_nulls.csv\"))\n",
        "    if 'target' in df.columns:\n",
        "        df['target'].value_counts(dropna=False).to_csv(os.path.join(out_dir, \"snapshot_target_counts.csv\"))\n",
        "        (df['target'].value_counts(normalize=True) * 100).round(2).to_csv(\n",
        "            os.path.join(out_dir, \"snapshot_target_perc.csv\")\n",
        "        )\n",
        "    sample_df.to_csv(os.path.join(out_dir, \"snapshot_sample.csv\"), index=False)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 2) PREPROCESAMIENTO (PARTE 2)\n",
        "#    Objetivo:\n",
        "#     - minúsculas, quitar URL y menciones\n",
        "#     - conservar la PALABRA del hashtag (remover solo '#')\n",
        "#     - tratar emojis/símbolos\n",
        "#     - preservar \"911\" como token (ej. 'nineoneone') para no perder semántica\n",
        "#     - remover números sueltos (con excepción del token preservado)\n",
        "#     - eliminar stopwords y lematizar\n",
        "#     - ejemplos Antes/Después\n",
        "# ----------------------------------------------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "STOPWORDS = set(w for w in stopwords.words('english') if w not in {\"no\",\"not\",\"never\"})\n",
        "\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"Limpia y normaliza texto siguiendo las decisiones del avance.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # 1) Unescape y minúsculas\n",
        "    text = html.unescape(str(text)).lower()\n",
        "\n",
        "    # 2) Conservar palabra del hashtag: quitar el símbolo '#' pero no la palabra\n",
        "    text = re.sub(r'#', ' ', text)\n",
        "\n",
        "    # 3) Quitar URLs y menciones\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text)\n",
        "    text = re.sub(r'@\\w+', ' ', text)\n",
        "\n",
        "    # 4) Quitar emojis/símbolos del plano multilingüe\n",
        "    text = re.sub(r'[\\U00010000-\\U0010FFFF]', ' ', text)  # emojis extendidos\n",
        "\n",
        "    # 5) Dejar solo letras/números/espacios (remover punct)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "\n",
        "    # 6) Preservar \"911\" como palabra informativa (marcado temporal)\n",
        "    text = re.sub(r'\\b911\\b', ' nineoneone ', text)\n",
        "\n",
        "    # 7) Tokenizar\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 8) Remover números sueltos (excepto nuestro marcador)\n",
        "    tokens = [t for t in tokens if not (t.isdigit() and t != 'nineoneone')]\n",
        "\n",
        "    # 9) Stopwords + Lematización\n",
        "    clean = []\n",
        "    for w in tokens:\n",
        "        if w in STOPWORDS:\n",
        "            continue\n",
        "        base = lemmatizer.lemmatize(w)\n",
        "        clean.append(base)\n",
        "\n",
        "    return ' '.join(clean)\n",
        "\n",
        "\n",
        "def demo_preprocess_examples(df: pd.DataFrame, k: int = 5) -> None:\n",
        "    \"\"\"Imprime ejemplos Antes/Después para documentar el efecto del preprocesamiento.\"\"\"\n",
        "    print(\"\\n=== EJEMPLOS ANTES/DESPUÉS (Preprocesamiento) ===\")\n",
        "    if 'text' not in df.columns:\n",
        "        print(\"⚠️ Columna 'text' no encontrada. No se pueden generar ejemplos.\")\n",
        "        return\n",
        "    examples = df['text'].dropna().sample(min(k, df['text'].dropna().shape[0]), random_state=13).tolist()\n",
        "    for raw in examples:\n",
        "        print(\"\\nRAW  :\", raw)\n",
        "        print(\"CLEAN:\", preprocess_text(raw))\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# 3) UNIGRAMAS POR CLASE + WORDCLOUD + BARRAS TOP-10 (PARTE 3)\n",
        "# ----------------------------------------------------------------\n",
        "def get_word_frequencies(text_series: pd.Series) -> Counter:\n",
        "    all_words = ' '.join(text_series.astype(str)).split()\n",
        "    return Counter(all_words)\n",
        "\n",
        "def save_wordcloud_and_barchart(freq: Counter, title: str, out_prefix: str, topn: int = 10) -> None:\n",
        "    \"\"\"Genera y guarda WordCloud y gráfico de barras Top-N a disco.\"\"\"\n",
        "    # WordCloud\n",
        "    wc = WordCloud(width=1000, height=500, background_color='white').generate_from_frequencies(freq)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'WordCloud - {title}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, f\"{out_prefix}_wordcloud.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Barras Top-N\n",
        "    top_items = dict(freq.most_common(topn))\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(top_items.keys(), top_items.values())\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title(f'Top {topn} Words - {title}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, f\"{out_prefix}_top{topn}_bar.png\"))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 4) BIGRAMAS / TRIGRAMAS POR CLASE (PARTE 4)\n",
        "# ---------------------------------------------------\n",
        "def get_bigram_frequencies(text_series: pd.Series) -> Counter:\n",
        "    all_bigrams = []\n",
        "    for text in text_series.astype(str):\n",
        "        toks = text.split()\n",
        "        all_bigrams.extend(list(bigrams(toks)))\n",
        "    return Counter(all_bigrams)\n",
        "\n",
        "def get_trigram_frequencies(text_series: pd.Series) -> Counter:\n",
        "    all_trigrams = []\n",
        "    for text in text_series.astype(str):\n",
        "        toks = text.split()\n",
        "        all_trigrams.extend(list(trigrams(toks)))\n",
        "    return Counter(all_trigrams)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) MODELO PRELIMINAR (PARTE 5)\n",
        "#    - Split estratificado\n",
        "#    - TF-IDF (1-2-gramas)\n",
        "#    - Regresión Logística\n",
        "#    - Métricas + Matriz de Confusión + Error Analysis\n",
        "# ------------------------------------------------------------\n",
        "def baseline_model(df_clean: pd.DataFrame) -> None:\n",
        "    if 'cleaned_text' not in df_clean.columns or 'target' not in df_clean.columns:\n",
        "        print(\"⚠️ Faltan columnas 'cleaned_text' y/o 'target'. No se entrena baseline.\")\n",
        "        return\n",
        "\n",
        "    X = df_clean['cleaned_text'].fillna(\"\")\n",
        "    y = df_clean['target'].astype(int)\n",
        "\n",
        "    # Split estratificado\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Vectorizador: unigrams + bigrams\n",
        "    vec = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=20000)\n",
        "    Xtr = vec.fit_transform(X_train)\n",
        "    Xva = vec.transform(X_valid)\n",
        "\n",
        "    # Regresión Logística (solver robusto; aumentar max_iter para convergencia)\n",
        "    clf = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "    clf.fit(Xtr, y_train)\n",
        "    pred = clf.predict(Xva)\n",
        "\n",
        "    print(\"\\n=== MÉTRICAS (Validación) ===\")\n",
        "    print(classification_report(y_valid, pred, digits=4))\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_valid, pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
        "    fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    disp.plot(ax=ax, values_format='d')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Mini error analysis (hasta 5)\n",
        "    miss_idx = np.where(pred != y_valid.values)[0][:5]\n",
        "    print(\"\\n=== ERRORES DE EJEMPLO ===\")\n",
        "    for i in miss_idx:\n",
        "        print(f\"\\nTrue={y_valid.values[i]} Pred={pred[i]}\")\n",
        "        print(X_valid.iloc[i])\n",
        "\n",
        "    vocab = pd.Series(vec.vocabulary_).sort_values()\n",
        "    vocab.to_csv(os.path.join(OUT_DIR, \"tfidf_vocabulary.csv\"))\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# MAIN: ORQUESTA TODO EL FLUJO\n",
        "# ==============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # ---- Cargar dataset ----\n",
        "\n",
        "    df = pd.read_csv(\"tweets.csv\")\n",
        "\n",
        "    # ---- Parte 1: Snapshot ----\n",
        "    snapshot_dataset(df, OUT_DIR)\n",
        "\n",
        "    # ---- Parte 2: Preprocesamiento ----\n",
        "    print(\"Aplicando preprocesamiento a la columna 'text' -> 'cleaned_text' ...\")\n",
        "    if 'text' not in df.columns:\n",
        "        raise ValueError(\"El CSV debe contener la columna 'text'.\")\n",
        "    demo_preprocess_examples(df, k=5)\n",
        "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "    # Guardar preprocesado\n",
        "    clean_path = os.path.join(OUT_DIR, \"tweets_cleaned.csv\")\n",
        "    df.to_csv(clean_path, index=False)\n",
        "    print(f\"Archivo preprocesado guardado en: {clean_path}\")\n",
        "\n",
        "    # ---- Parte 3: Unigramas por clase ----\n",
        "    if 'target' in df.columns:\n",
        "        disaster = df[df['target'] == 1]['cleaned_text']\n",
        "        non_disaster = df[df['target'] == 0]['cleaned_text']\n",
        "\n",
        "        # Frecuencias\n",
        "        disaster_freq = get_word_frequencies(disaster)\n",
        "        non_disaster_freq = get_word_frequencies(non_disaster)\n",
        "\n",
        "        # Exportar CSVs\n",
        "        pd.DataFrame(disaster_freq.items(), columns=['word', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"unigrams_disaster.csv\"), index=False\n",
        "        )\n",
        "        pd.DataFrame(non_disaster_freq.items(), columns=['word', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"unigrams_non_disaster.csv\"), index=False\n",
        "        )\n",
        "\n",
        "        # Visuales (WordCloud + Barras)\n",
        "        save_wordcloud_and_barchart(disaster_freq, \"Disaster (target=1)\", \"disaster_unigrams\", topn=10)\n",
        "        save_wordcloud_and_barchart(non_disaster_freq, \"Non-Disaster (target=0)\", \"non_disaster_unigrams\", topn=10)\n",
        "\n",
        "        print(\"Top 10 palabras disaster:\", disaster_freq.most_common(10))\n",
        "        print(\"Top 10 palabras non-disaster:\", non_disaster_freq.most_common(10))\n",
        "        print(\"Palabras en común (unigrams):\", set(disaster_freq.keys()) & set(non_disaster_freq.keys()))\n",
        "    else:\n",
        "        print(\"⚠️ Columna 'target' no encontrada. Se omite análisis por clase (Partes 3-5).\")\n",
        "\n",
        "    # ---- Parte 4: Bigramas / Trigramas por clase ----\n",
        "    if 'target' in df.columns:\n",
        "        disaster_bigram = get_bigram_frequencies(disaster)\n",
        "        non_disaster_bigram = get_bigram_frequencies(non_disaster)\n",
        "        disaster_trigram = get_trigram_frequencies(disaster)\n",
        "        non_disaster_trigram = get_trigram_frequencies(non_disaster)\n",
        "\n",
        "        # Exportar CSVs\n",
        "        pd.DataFrame([(' '.join(k), v) for k, v in disaster_bigram.items()],\n",
        "                     columns=['bigram', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"bigrams_disaster.csv\"), index=False\n",
        "        )\n",
        "        pd.DataFrame([(' '.join(k), v) for k, v in non_disaster_bigram.items()],\n",
        "                     columns=['bigram', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"bigrams_non_disaster.csv\"), index=False\n",
        "        )\n",
        "        pd.DataFrame([(' '.join(k), v) for k, v in disaster_trigram.items()],\n",
        "                     columns=['trigram', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"trigrams_disaster.csv\"), index=False\n",
        "        )\n",
        "        pd.DataFrame([(' '.join(k), v) for k, v in non_disaster_trigram.items()],\n",
        "                     columns=['trigram', 'count']).to_csv(\n",
        "            os.path.join(OUT_DIR, \"trigrams_non_disaster.csv\"), index=False\n",
        "        )\n",
        "\n",
        "        print(\"Top 10 bigramas disaster:\", disaster_bigram.most_common(10))\n",
        "        print(\"Top 10 bigramas non-disaster:\", non_disaster_bigram.most_common(10))\n",
        "        print(\"Top 10 trigramas disaster:\", disaster_trigram.most_common(10))\n",
        "        print(\"Top 10 trigramas non-disaster:\", non_disaster_trigram.most_common(10))\n",
        "\n",
        "    # ---- Parte 5: Modelo preliminar ----\n",
        "    if 'target' in df.columns:\n",
        "        baseline_model(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "69ddd4ac",
      "metadata": {
        "id": "69ddd4ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd868328-4f06-458e-8e5c-7d8a6b886ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mejor modelo por F1: LinearSVM | Params: {'clf__C': 0.5}\n",
            "\n",
            "== Classification report ==\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8206    0.8631    0.8413       869\n",
            "           1     0.8046    0.7492    0.7759       654\n",
            "\n",
            "    accuracy                         0.8142      1523\n",
            "   macro avg     0.8126    0.8061    0.8086      1523\n",
            "weighted avg     0.8137    0.8142    0.8132      1523\n",
            "\n",
            "== Confusion matrix ==\n",
            "[[750 119]\n",
            " [164 490]]\n",
            "\n",
            "Top + (asoc. a clase 1 = desastre):\n",
            "hiroshima                 2.1612\n",
            "fires                     1.7468\n",
            "storm                     1.6168\n",
            "floods                    1.5633\n",
            "in                        1.5514\n",
            "wildfire                  1.5429\n",
            "train                     1.4685\n",
            "near                      1.4378\n",
            "massacre                  1.4345\n",
            "earthquake                1.4066\n",
            "tornado                   1.3945\n",
            "buildings                 1.3363\n",
            "california                1.3292\n",
            "police                    1.3017\n",
            "japan                     1.2729\n",
            "fire                      1.2725\n",
            "typhoon                   1.2538\n",
            "forest                    1.2405\n",
            "bombing                   1.2365\n",
            "casualties                1.2089\n",
            "\n",
            "Top - (asoc. a clase 0 = no desastre):\n",
            "you                       -1.7525\n",
            "my                        -1.2824\n",
            "new                       -1.1674\n",
            "upheaval                  -1.0412\n",
            "nowplaying                -1.0205\n",
            "myself                    -0.9927\n",
            "stretcher                 -0.9691\n",
            "finally                   -0.9216\n",
            "full                      -0.9113\n",
            "blizzard                  -0.9052\n",
            "show                      -0.8993\n",
            "traumatised               -0.8713\n",
            "deluge                    -0.8652\n",
            "cake                      -0.8570\n",
            "let                       -0.8465\n",
            "or                        -0.8455\n",
            "mayhem                    -0.8380\n",
            "bloody                    -0.8069\n",
            "never                     -0.8000\n",
            "fuck                      -0.7959\n",
            "\n",
            "Modelo guardado en: modelo_disaster_best.joblib\n"
          ]
        }
      ],
      "source": [
        "# === Punto 6: Modelos de clasificación para \"disaster\" (1) vs \"no disaster\" (0) ===\n",
        "# - Pipelines con TF-IDF (unigramas + bigramas) para capturar contexto corto.\n",
        "# - Modelos: Multinomial Naive Bayes, Regresión Logística, Linear SVM, Random Forest (baseline).\n",
        "# - Búsqueda rápida de hiperparámetros (GridSearchCV) y evaluación con métricas.\n",
        "# - Guarda el mejor modelo para usarlo en el Punto 7 (función clasificar_tweet).\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# 1) Tomar el DataFrame existente\n",
        "\n",
        "df = globals().get('df', None)\n",
        "if df is None:\n",
        "    # fallback opcional: si no tienes df en memoria, intenta cargar train.csv desde el cwd\n",
        "    df = pd.read_csv('train.csv')  # ajusta la ruta si la tienes en otra carpeta\n",
        "\n",
        "text_col = 'clean_text' if 'clean_text' in df.columns else 'text'\n",
        "target_col = 'target'\n",
        "\n",
        "# Asegurar tipos\n",
        "df[text_col] = df[text_col].astype(str)\n",
        "y = df[target_col].astype(int)\n",
        "X = df[text_col]\n",
        "\n",
        "# 2) Split estratificado (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Vectorizador base (palabras): unigrams + bigrams para dar algo de \"contexto\"\n",
        "base_tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2,\n",
        "    max_df=0.98,\n",
        "    strip_accents='unicode',\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "# 4) Definir modelos (pipelines)\n",
        "pipelines = {\n",
        "    \"NaiveBayes\": Pipeline([\n",
        "        (\"tfidf\", base_tfidf),\n",
        "        (\"clf\", MultinomialNB())\n",
        "    ]),\n",
        "    \"LogisticRegression\": Pipeline([\n",
        "        (\"tfidf\", base_tfidf),\n",
        "        (\"clf\", LogisticRegression(max_iter=200, n_jobs=None))\n",
        "    ]),\n",
        "    \"LinearSVM\": Pipeline([\n",
        "        (\"tfidf\", base_tfidf),\n",
        "        (\"clf\", LinearSVC())\n",
        "    ]),\n",
        "    \"RandomForest\": Pipeline([\n",
        "        (\"tfidf\", base_tfidf),\n",
        "        (\"clf\", RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# 5) Grids pequeños (rápidos) para no tardar demasiado\n",
        "param_grids = {\n",
        "    \"NaiveBayes\": {\n",
        "        \"clf__alpha\": [0.5, 1.0]\n",
        "    },\n",
        "    \"LogisticRegression\": {\n",
        "        \"clf__C\": [0.5, 1.0, 2.0],\n",
        "        \"clf__penalty\": [\"l2\"],\n",
        "        \"clf__solver\": [\"liblinear\", \"lbfgs\"]  # lbfgs ignora 'penalty' si no es l2, por eso fijamos l2\n",
        "    },\n",
        "    \"LinearSVM\": {\n",
        "        \"clf__C\": [0.5, 1.0, 2.0]\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"clf__max_depth\": [None, 20, 40],\n",
        "        \"clf__min_samples_split\": [2, 5]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 6) Entrenar, evaluar y comparar\n",
        "results = []\n",
        "best_models = {}\n",
        "\n",
        "for name, pipe in pipelines.items():\n",
        "    grid = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grids[name],\n",
        "        scoring=\"f1\",  # F1 balancea precision/recall (dataset algo desbalanceado)\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    y_pred = grid.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", zero_division=0)\n",
        "\n",
        "    results.append({\n",
        "        \"modelo\": name,\n",
        "        \"best_params\": grid.best_params_,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    best_models[name] = grid\n",
        "\n",
        "# 7) Tabla de resultados ordenada por F1\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"f1\", ascending=False).reset_index(drop=True)\n",
        "results_df\n",
        "\n",
        "# 8) Mostrar reporte y matriz de confusión del mejor\n",
        "best_name = results_df.iloc[0][\"modelo\"]\n",
        "print(f\"\\nMejor modelo por F1: {best_name} | Params: {best_models[best_name].best_params_}\\n\")\n",
        "\n",
        "best_clf = best_models[best_name]\n",
        "y_pred_best = best_clf.predict(X_test)\n",
        "\n",
        "print(\"== Classification report ==\\n\")\n",
        "print(classification_report(y_test, y_pred_best, digits=4))\n",
        "\n",
        "print(\"== Confusion matrix ==\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "# 9) (Opcional) Inspección de características top del mejor modelo si es lineal (LR o SVM)\n",
        "def top_features_linear(grid, top_k=20):\n",
        "    try:\n",
        "        vec = grid.best_estimator_[\"tfidf\"]\n",
        "        clf = grid.best_estimator_[\"clf\"]\n",
        "        if hasattr(clf, \"coef_\"):\n",
        "            feature_names = np.array(vec.get_feature_names_out())\n",
        "            coefs = clf.coef_.ravel()\n",
        "            top_pos_idx = np.argsort(coefs)[-top_k:][::-1]\n",
        "            top_neg_idx = np.argsort(coefs)[:top_k]\n",
        "            print(\"\\nTop + (asoc. a clase 1 = desastre):\")\n",
        "            for i in top_pos_idx:\n",
        "                print(f\"{feature_names[i]:<25s} {coefs[i]:.4f}\")\n",
        "            print(\"\\nTop - (asoc. a clase 0 = no desastre):\")\n",
        "            for i in top_neg_idx:\n",
        "                print(f\"{feature_names[i]:<25s} {coefs[i]:.4f}\")\n",
        "        else:\n",
        "            print(\"El clasificador no es lineal o no expone coeficientes.\")\n",
        "    except Exception as e:\n",
        "        print(f\"No se pudieron extraer features: {e}\")\n",
        "\n",
        "if best_name in [\"LogisticRegression\", \"LinearSVM\"]:\n",
        "    top_features_linear(best_models[best_name], top_k=20)\n",
        "\n",
        "# 10) Guardar el mejor modelo para el Punto 7\n",
        "joblib.dump(best_clf.best_estimator_, \"modelo_disaster_best.joblib\")\n",
        "print(\"\\nModelo guardado en: modelo_disaster_best.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Punto 7: Función para clasificar un tweet nuevo ===\n",
        "# - Carga el mejor modelo (Pipeline TF-IDF + clf).\n",
        "# - Usa tu preprocess_text si ya existe en el notebook; si no, aplica una limpieza equivalente.\n",
        "# - Devuelve etiqueta (0/1), texto limpio y una \"confianza\" (score sigmoide del margin SVM).\n",
        "\n",
        "import re, html, joblib, numpy as np, pandas as pd\n",
        "\n",
        "# 1) Cargar el modelo entrenado\n",
        "MODEL_PATH = \"modelo_disaster_best.joblib\"\n",
        "modelo = joblib.load(MODEL_PATH)\n",
        "\n",
        "# 2) Fallback de preprocesamiento\n",
        "def _default_preprocess(text: str) -> str:\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    t = html.unescape(str(text)).lower()\n",
        "    # conservar palabra del hashtag\n",
        "    t = re.sub(r'#', ' ', t)\n",
        "    # quitar URLs y menciones\n",
        "    t = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', t)\n",
        "    t = re.sub(r'@\\w+', ' ', t)\n",
        "    # preservar 911 como token legible\n",
        "    t = re.sub(r'\\b911\\b', ' nineoneone ', t)\n",
        "    # quitar puntuación y números sueltos\n",
        "    t = re.sub(r'[^\\w\\s]', ' ', t)  # puntuación\n",
        "    t = re.sub(r'\\d+', ' ', t)      # números\n",
        "    # espacios\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    return t\n",
        "\n",
        "_preprocess_fn = globals().get('preprocess_text', _default_preprocess)\n",
        "\n",
        "# 3) Función principal\n",
        "def clasificar_tweet(tweet: str) -> dict:\n",
        "    \"\"\"\n",
        "    Recibe un tweet crudo y devuelve:\n",
        "      - pred: 1 = desastre, 0 = no desastre\n",
        "      - label: 'disaster'/'no disaster'\n",
        "      - clean: texto preprocesado\n",
        "      - confidence: score ∈ (0,1) derivado de decision_function (no calibrado)\n",
        "    \"\"\"\n",
        "    clean = _preprocess_fn(tweet)\n",
        "    pred = int(modelo.predict([clean])[0])\n",
        "\n",
        "    # \"confianza\" basada en margin (sigmoide del decision_function).\n",
        "    confidence = None\n",
        "    if hasattr(modelo, \"decision_function\"):\n",
        "        margin = float(modelo.decision_function([clean])[0])\n",
        "        confidence = float(1.0 / (1.0 + np.exp(-margin)))  # monotónica, no calibrada\n",
        "    elif hasattr(modelo, \"predict_proba\"):\n",
        "        confidence = float(modelo.predict_proba([clean])[0][1])\n",
        "\n",
        "    return {\n",
        "        \"tweet\": tweet,\n",
        "        \"clean\": clean,\n",
        "        \"pred\": pred,\n",
        "        \"label\": \"disaster\" if pred == 1 else \"no disaster\",\n",
        "        \"confidence\": None if confidence is None else round(confidence, 4),\n",
        "    }\n",
        "\n",
        "# 4) Clasificador por lotes (útil para probar varios)\n",
        "def clasificar_varios(tweets: list[str]) -> pd.DataFrame:\n",
        "    cleans = [ _preprocess_fn(t) for t in tweets ]\n",
        "    preds = modelo.predict(cleans)\n",
        "    # intentar confianza si se puede\n",
        "    confs = None\n",
        "    if hasattr(modelo, \"decision_function\"):\n",
        "        margins = modelo.decision_function(cleans)\n",
        "        confs = 1.0 / (1.0 + np.exp(-np.asarray(margins, dtype=float)))\n",
        "    elif hasattr(modelo, \"predict_proba\"):\n",
        "        confs = modelo.predict_proba(cleans)[:, 1]\n",
        "    df_out = pd.DataFrame({\n",
        "        \"tweet\": tweets,\n",
        "        \"clean\": cleans,\n",
        "        \"pred\": preds.astype(int),\n",
        "        \"label\": np.where(preds==1, \"disaster\", \"no disaster\"),\n",
        "    })\n",
        "    if confs is not None:\n",
        "        df_out[\"confidence\"] = np.round(confs, 4)\n",
        "    return df_out\n",
        "\n",
        "# 5) Prueba rápida\n",
        "ejemplos = [\n",
        "    \"Wildfire spreading near the hills, people evacuating now!\",\n",
        "    \"This cake is a disaster 😂 but tastes amazing lol\",\n",
        "    \"Earthquake reported 20 miles north of the city. Stay safe.\",\n",
        "]\n",
        "clasificar_varios(ejemplos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "P7xB3k2Hqkpd",
        "outputId": "9c0ac2ed-f841-4f8c-df92-12ad09edcb9a"
      },
      "id": "P7xB3k2Hqkpd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  \\\n",
              "0  Wildfire spreading near the hills, people evac...   \n",
              "1   This cake is a disaster 😂 but tastes amazing lol   \n",
              "2  Earthquake reported 20 miles north of the city...   \n",
              "\n",
              "                                            clean  pred        label  \\\n",
              "0  wildfire spreading near hill people evacuating     1     disaster   \n",
              "1                 cake disaster taste amazing lol     0  no disaster   \n",
              "2   earthquake reported mile north city stay safe     1     disaster   \n",
              "\n",
              "   confidence  \n",
              "0      0.7693  \n",
              "1      0.2767  \n",
              "2      0.7094  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1640b181-b7f9-44f3-9a7c-6391f6fa82ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean</th>\n",
              "      <th>pred</th>\n",
              "      <th>label</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wildfire spreading near the hills, people evac...</td>\n",
              "      <td>wildfire spreading near hill people evacuating</td>\n",
              "      <td>1</td>\n",
              "      <td>disaster</td>\n",
              "      <td>0.7693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This cake is a disaster 😂 but tastes amazing lol</td>\n",
              "      <td>cake disaster taste amazing lol</td>\n",
              "      <td>0</td>\n",
              "      <td>no disaster</td>\n",
              "      <td>0.2767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Earthquake reported 20 miles north of the city...</td>\n",
              "      <td>earthquake reported mile north city stay safe</td>\n",
              "      <td>1</td>\n",
              "      <td>disaster</td>\n",
              "      <td>0.7094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1640b181-b7f9-44f3-9a7c-6391f6fa82ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1640b181-b7f9-44f3-9a7c-6391f6fa82ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1640b181-b7f9-44f3-9a7c-6391f6fa82ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b7623e2d-b765-42de-9896-754338944d6c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7623e2d-b765-42de-9896-754338944d6c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b7623e2d-b765-42de-9896-754338944d6c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"clasificar_varios(ejemplos)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Wildfire spreading near the hills, people evacuating now!\",\n          \"This cake is a disaster \\ud83d\\ude02 but tastes amazing lol\",\n          \"Earthquake reported 20 miles north of the city. Stay safe.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"wildfire spreading near hill people evacuating\",\n          \"cake disaster taste amazing lol\",\n          \"earthquake reported mile north city stay safe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no disaster\",\n          \"disaster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.268784938814163,\n        \"min\": 0.2767,\n        \"max\": 0.7693,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7693,\n          0.2767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Punto 8: Análisis de sentimiento (positivo/negativo/neutral) ===\n",
        "# - Usa VADER (NLTK). Si no está disponible, cae a TextBlob.\n",
        "# - PRESERVA emojis y emoticonos (no usamos 'clean_text' aquí), quitamos solo URLs/mentions.\n",
        "# - Devuelve: sent_neg, sent_neu, sent_pos, sent_compound, sent_label (pos/neu/neg),\n",
        "#             pos_count, neg_count (conteos de palabras según léxico).\n",
        "\n",
        "import re, html, numpy as np, pandas as pd\n",
        "\n",
        "# 0) Asegurar df y columnas\n",
        "assert 'text' in df.columns, \"No encuentro la columna 'text' en df.\"\n",
        "if 'target' not in df.columns:\n",
        "    raise ValueError(\"No encuentro la columna 'target' en df.\")\n",
        "\n",
        "# 1) Preprocesamiento ligero SOLO para sentimiento (conservar emojis y 'tonos')\n",
        "def sentiment_prepare(s: str) -> str:\n",
        "    \"\"\"Mantiene emojis/emoticonos; quita URLs y @mentions; conserva hashtags como palabra.\"\"\"\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    t = str(s)\n",
        "    t = html.unescape(t)\n",
        "    # quitar URLs y menciones\n",
        "    t = re.sub(r'http\\S+|www\\S+|https?\\S+', ' ', t)\n",
        "    t = re.sub(r'@\\w+', ' ', t)\n",
        "    # convertir #palabra -> palabra (conserva la palabra)\n",
        "    t = t.replace('#', ' ')\n",
        "    # colapsar espacios\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    return t\n",
        "\n",
        "df['text_for_sent'] = df['text'].astype(str).apply(sentiment_prepare)\n",
        "\n",
        "# 2) Backend de sentimiento: VADER -> TextBlob (fallback)\n",
        "backend = None\n",
        "sia = None\n",
        "try:\n",
        "    import nltk\n",
        "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "    try:\n",
        "        _ = SentimentIntensityAnalyzer()\n",
        "    except LookupError:\n",
        "        nltk.download('vader_lexicon')\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    backend = \"vader\"\n",
        "except Exception as e:\n",
        "    try:\n",
        "        from textblob import TextBlob\n",
        "        backend = \"textblob\"\n",
        "    except Exception as e2:\n",
        "        raise RuntimeError(\"No se encontró VADER ni TextBlob. Instala al menos uno para continuar.\")\n",
        "\n",
        "print(f\"Usando backend de sentimiento: {backend}\")\n",
        "\n",
        "# 3) Funciones de puntaje y conteo de palabras positivas/negativas\n",
        "def scores_vader(txt: str):\n",
        "    sc = sia.polarity_scores(txt)  # dict: neg, neu, pos, compound\n",
        "    return sc['neg'], sc['neu'], sc['pos'], sc['compound']\n",
        "\n",
        "def counts_vader(txt: str):\n",
        "    # cuenta tokens cuya valencia en el léxico VADER sea >0 o <0\n",
        "    tokens = re.findall(r\"\\w+\", txt.lower())\n",
        "    pos = sum(1 for t in tokens if t in sia.lexicon and sia.lexicon[t] > 0)\n",
        "    neg = sum(1 for t in tokens if t in sia.lexicon and sia.lexicon[t] < 0)\n",
        "    return pos, neg\n",
        "\n",
        "def scores_textblob(txt: str):\n",
        "    from textblob import TextBlob\n",
        "    pol = TextBlob(txt).sentiment.polarity  # [-1,1]\n",
        "    # aproximación a componentes\n",
        "    pos = max(0.0, pol)\n",
        "    neg = max(0.0, -pol)\n",
        "    neu = max(0.0, 1.0 - (pos + neg))\n",
        "    return neg, neu, pos, float(pol)\n",
        "\n",
        "def counts_textblob(txt: str):\n",
        "    from textblob import TextBlob\n",
        "    tokens = re.findall(r\"\\w+\", txt.lower())\n",
        "    pos = neg = 0\n",
        "    for t in tokens:\n",
        "        pol = TextBlob(t).sentiment.polarity\n",
        "        if pol > 0:\n",
        "            pos += 1\n",
        "        elif pol < 0:\n",
        "            neg += 1\n",
        "    return pos, neg\n",
        "\n",
        "if backend == \"vader\":\n",
        "    score_fn = scores_vader\n",
        "    count_fn = counts_vader\n",
        "else:\n",
        "    score_fn = scores_textblob\n",
        "    count_fn = counts_textblob\n",
        "\n",
        "# 4) Aplicar a todo el dataset\n",
        "neg_neu_pos_comp = df['text_for_sent'].apply(score_fn)\n",
        "df[['sent_neg','sent_neu','sent_pos','sent_compound']] = pd.DataFrame(neg_neu_pos_comp.tolist(), index=df.index)\n",
        "\n",
        "pos_neg_counts = df['text_for_sent'].apply(count_fn)\n",
        "df[['pos_count','neg_count']] = pd.DataFrame(pos_neg_counts.tolist(), index=df.index)\n",
        "\n",
        "# 5) Etiqueta de sentimiento por umbrales estándar de VADER (funcionan también con fallback)\n",
        "def label_from_compound(c):\n",
        "    if c >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif c <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "df['sent_label'] = df['sent_compound'].apply(label_from_compound)\n",
        "\n",
        "# 6) Resumen rápido (para tu informe)\n",
        "print(df[['sent_neg','sent_neu','sent_pos','sent_compound','pos_count','neg_count','sent_label']].head())\n",
        "\n",
        "print(\"\\nDistribución de sentimiento (tweets):\")\n",
        "print(df['sent_label'].value_counts(dropna=False).to_frame('count'))\n",
        "\n",
        "print(\"\\nCrosstab sentimiento vs. target (0=no desastre, 1=desastre):\")\n",
        "print(pd.crosstab(df['sent_label'], df['target']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7rQC1oGrQQJ",
        "outputId": "e0b7abb8-50ea-4a40-fada-0ec131ebe004"
      },
      "id": "D7rQC1oGrQQJ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando backend de sentimiento: vader\n",
            "   sent_neg  sent_neu  sent_pos  sent_compound  pos_count  neg_count  \\\n",
            "0     0.000     0.851     0.149         0.2732          1          0   \n",
            "1     0.286     0.714     0.000        -0.3400          0          1   \n",
            "2     0.095     0.905     0.000        -0.2960          0          1   \n",
            "3     0.000     1.000     0.000         0.0000          0          0   \n",
            "4     0.000     1.000     0.000         0.0000          0          0   \n",
            "\n",
            "  sent_label  \n",
            "0   positive  \n",
            "1   negative  \n",
            "2   negative  \n",
            "3    neutral  \n",
            "4    neutral  \n",
            "\n",
            "Distribución de sentimiento (tweets):\n",
            "            count\n",
            "sent_label       \n",
            "negative     3735\n",
            "neutral      1945\n",
            "positive     1933\n",
            "\n",
            "Crosstab sentimiento vs. target (0=no desastre, 1=desastre):\n",
            "target         0     1\n",
            "sent_label            \n",
            "negative    1854  1881\n",
            "neutral     1092   853\n",
            "positive    1396   537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Punto 9: Top 10 más negativos/positivos + comparación por categoría ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 0) Asegurar columnas necesarias\n",
        "req_cols = {'id','text','target','sent_compound','sent_label'}\n",
        "faltan = req_cols - set(df.columns)\n",
        "if faltan:\n",
        "    raise ValueError(f\"Faltan columnas en df para el punto 9: {faltan}\")\n",
        "\n",
        "# 1) Etiqueta humana de categoría\n",
        "df['target_label'] = np.where(df['target']==1, 'desastre', 'no desastre')\n",
        "\n",
        "# 2) Top 10 más negativos / más positivos (según sent_compound)\n",
        "cols_show = ['id','target','target_label','sent_label','sent_compound','text']\n",
        "\n",
        "top10_neg = df.sort_values('sent_compound', ascending=True).head(10)[cols_show]\n",
        "top10_pos = df.sort_values('sent_compound', ascending=False).head(10)[cols_show]\n",
        "\n",
        "print(\"=== TOP 10 TWEETS MÁS NEGATIVOS ===\")\n",
        "display(top10_neg.reset_index(drop=True))\n",
        "\n",
        "print(\"\\n=== TOP 10 TWEETS MÁS POSITIVOS ===\")\n",
        "display(top10_pos.reset_index(drop=True))\n",
        "\n",
        "# 3) ¿Son los de desastre más negativos?\n",
        "#    Tasas por categoría\n",
        "totals = df.groupby('target').size().rename('total')\n",
        "negatives = df[df['sent_label']=='negative'].groupby('target').size().rename('negativos')\n",
        "positives = df[df['sent_label']=='positive'].groupby('target').size().rename('positivos')\n",
        "neutrals  = df[df['sent_label']=='neutral'].groupby('target').size().rename('neutrales')\n",
        "\n",
        "summary = pd.concat([totals, negatives, positives, neutrals], axis=1).fillna(0).astype(int)\n",
        "summary['p_neg'] = summary['negativos'] / summary['total']\n",
        "summary['p_pos'] = summary['positivos'] / summary['total']\n",
        "summary['p_neu'] = summary['neutrales'] / summary['total']\n",
        "\n",
        "print(\"\\n=== Resumen por categoría (0=no desastre, 1=desastre) ===\")\n",
        "display(summary)\n",
        "\n",
        "p_neg_0 = summary.loc[0,'p_neg']\n",
        "p_neg_1 = summary.loc[1,'p_neg']\n",
        "print(f\"\\nTasa de negativos en NO DESASTRE (0): {p_neg_0:.3f}\")\n",
        "print(f\"Tasa de negativos en DESASTRE (1):   {p_neg_1:.3f}\")\n",
        "print(f\"Diferencia (1 - 0): {p_neg_1 - p_neg_0:+.3f}\")\n",
        "\n",
        "# 4) (Opcional) Significancia estadística: Chi-cuadrado y Cramér's V\n",
        "try:\n",
        "    from scipy.stats import chi2_contingency\n",
        "    tab = pd.crosstab(df['target'], df['sent_label'])  # filas: target, columnas: sentiment\n",
        "    chi2, p, dof, exp = chi2_contingency(tab.values)\n",
        "    n = tab.values.sum()\n",
        "    k = min(tab.shape) - 1  # min(r-1,c-1)\n",
        "    cramer_v = np.sqrt(chi2 / (n * k)) if k > 0 else np.nan\n",
        "    print(\"\\n=== Chi-cuadrado sentimiento x categoría ===\")\n",
        "    print(tab)\n",
        "    print(f\"chi2={chi2:.3f}, dof={dof}, p-value={p:.3e}, Cramér's V={cramer_v:.3f}\")\n",
        "except Exception as e:\n",
        "    print(\"\\n(No se pudo calcular chi-cuadrado/Cramér V):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G48j84dhsFER",
        "outputId": "8a43b55b-5fed-4c3d-b51e-849769e2a7f2"
      },
      "id": "G48j84dhsFER",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TOP 10 TWEETS MÁS NEGATIVOS ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      id  target target_label sent_label  sent_compound  \\\n",
              "0  10689       0  no desastre   negative        -0.9883   \n",
              "1   9172       1     desastre   negative        -0.9686   \n",
              "2   9166       1     desastre   negative        -0.9623   \n",
              "3   9137       1     desastre   negative        -0.9595   \n",
              "4   9159       1     desastre   negative        -0.9552   \n",
              "5   4213       0  no desastre   negative        -0.9549   \n",
              "6    682       1     desastre   negative        -0.9538   \n",
              "7   2225       1     desastre   negative        -0.9524   \n",
              "8   9765       1     desastre   negative        -0.9500   \n",
              "9   9940       1     desastre   negative        -0.9493   \n",
              "\n",
              "                                                text  \n",
              "0  wreck? wreck wreck wreck wreck wreck wreck wre...  \n",
              "1  @Abu_Baraa1 Suicide bomber targets Saudi mosqu...  \n",
              "2  Suicide bomber kills 15 in Saudi security site...  \n",
              "3  ? 19th Day Since 17-Jul-2015 -- Nigeria: Suici...  \n",
              "4  17 killed in SÛªArabia mosque suicide bombing...  \n",
              "5  at the lake \\n*sees a dead fish*\\nme: poor lit...  \n",
              "6  illegal alien released by Obama/DHS 4 times Ch...  \n",
              "7  Bomb Crash Loot Riot Emergency Pipe Bomb Nucle...  \n",
              "8  Bomb head? Explosive decisions dat produced mo...  \n",
              "9  @cspan #Prez. Mr. President you are the bigges...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-167a2089-3720-4b46-88a9-30afd04d8a30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>target_label</th>\n",
              "      <th>sent_label</th>\n",
              "      <th>sent_compound</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10689</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9883</td>\n",
              "      <td>wreck? wreck wreck wreck wreck wreck wreck wre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9172</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9686</td>\n",
              "      <td>@Abu_Baraa1 Suicide bomber targets Saudi mosqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9166</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9623</td>\n",
              "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9137</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9595</td>\n",
              "      <td>? 19th Day Since 17-Jul-2015 -- Nigeria: Suici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9159</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9552</td>\n",
              "      <td>17 killed in SÛªArabia mosque suicide bombing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4213</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9549</td>\n",
              "      <td>at the lake \\n*sees a dead fish*\\nme: poor lit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>682</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>illegal alien released by Obama/DHS 4 times Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2225</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9524</td>\n",
              "      <td>Bomb Crash Loot Riot Emergency Pipe Bomb Nucle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9765</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9500</td>\n",
              "      <td>Bomb head? Explosive decisions dat produced mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9940</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.9493</td>\n",
              "      <td>@cspan #Prez. Mr. President you are the bigges...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-167a2089-3720-4b46-88a9-30afd04d8a30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-167a2089-3720-4b46-88a9-30afd04d8a30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-167a2089-3720-4b46-88a9-30afd04d8a30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b593acb4-ffed-4a1f-9016-ef5cf36d396b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b593acb4-ffed-4a1f-9016-ef5cf36d396b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b593acb4-ffed-4a1f-9016-ef5cf36d396b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\n(No se pudo calcular chi-cuadrado/Cram\\u00e9r V):\\\", e)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3610,\n        \"min\": 682,\n        \"max\": 10689,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9765,\n          9172,\n          4213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"desastre\",\n          \"no desastre\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_compound\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011723106338433598,\n        \"min\": -0.9883,\n        \"max\": -0.9493,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Bomb head? Explosive decisions dat produced more dead children than dead bodies trapped tween buildings on that day in September there\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TOP 10 TWEETS MÁS POSITIVOS ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      id  target target_label sent_label  sent_compound  \\\n",
              "0  10028       0  no desastre   positive         0.9730   \n",
              "1   9345       0  no desastre   positive         0.9564   \n",
              "2   8989       1     desastre   positive         0.9471   \n",
              "3   4541       0  no desastre   positive         0.9423   \n",
              "4   4844       0  no desastre   positive         0.9423   \n",
              "5   8994       0  no desastre   positive         0.9376   \n",
              "6   3525       1     desastre   positive         0.9356   \n",
              "7   1453       0  no desastre   positive         0.9345   \n",
              "8   9386       0  no desastre   positive         0.9344   \n",
              "9   8759       0  no desastre   positive         0.9300   \n",
              "\n",
              "                                                text  \n",
              "0  Check out 'Want Twister Tickets AND A VIP EXPE...  \n",
              "1  @thoutaylorbrown I feel like accidents are jus...  \n",
              "2  TodayÛªs storm will pass; let tomorrowÛªs li...  \n",
              "3  @batfanuk we enjoyed the show today. Great fun...  \n",
              "4  @batfanuk we enjoyed the show today. Great fun...  \n",
              "5  Free Ebay Sniping RT? http://t.co/B231Ul1O1K L...  \n",
              "6  @Raishimi33 :) well I think that sounds like a...  \n",
              "7  I'm not a Drake fan but I enjoy seeing him bod...  \n",
              "8  @duchovbutt @Starbuck_Scully @MadMakNY @davidd...  \n",
              "9  Super sweet and beautiful :) https://t.co/TUi9...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d80a6f5-1ad1-41ce-a042-9621cbe1bd5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>target_label</th>\n",
              "      <th>sent_label</th>\n",
              "      <th>sent_compound</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10028</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9730</td>\n",
              "      <td>Check out 'Want Twister Tickets AND A VIP EXPE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9345</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9564</td>\n",
              "      <td>@thoutaylorbrown I feel like accidents are jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8989</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9471</td>\n",
              "      <td>TodayÛªs storm will pass; let tomorrowÛªs li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4541</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9423</td>\n",
              "      <td>@batfanuk we enjoyed the show today. Great fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4844</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9423</td>\n",
              "      <td>@batfanuk we enjoyed the show today. Great fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8994</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9376</td>\n",
              "      <td>Free Ebay Sniping RT? http://t.co/B231Ul1O1K L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3525</td>\n",
              "      <td>1</td>\n",
              "      <td>desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9356</td>\n",
              "      <td>@Raishimi33 :) well I think that sounds like a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1453</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9345</td>\n",
              "      <td>I'm not a Drake fan but I enjoy seeing him bod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9386</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9344</td>\n",
              "      <td>@duchovbutt @Starbuck_Scully @MadMakNY @davidd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8759</td>\n",
              "      <td>0</td>\n",
              "      <td>no desastre</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>Super sweet and beautiful :) https://t.co/TUi9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d80a6f5-1ad1-41ce-a042-9621cbe1bd5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d80a6f5-1ad1-41ce-a042-9621cbe1bd5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d80a6f5-1ad1-41ce-a042-9621cbe1bd5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b23e1f32-16df-4c1d-91fc-92a74aba3b93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b23e1f32-16df-4c1d-91fc-92a74aba3b93')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b23e1f32-16df-4c1d-91fc-92a74aba3b93 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\n(No se pudo calcular chi-cuadrado/Cram\\u00e9r V):\\\", e)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3071,\n        \"min\": 1453,\n        \"max\": 10028,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9386,\n          9345,\n          8994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"desastre\",\n          \"no desastre\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_compound\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012890375393206267,\n        \"min\": 0.93,\n        \"max\": 0.973,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"@duchovbutt @Starbuck_Scully @MadMakNY @davidduchovny yeah we survived 9 seasons and 2 movies. Let's hope for the good. There's hope ??????\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resumen por categoría (0=no desastre, 1=desastre) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        total  negativos  positivos  neutrales     p_neg     p_pos     p_neu\n",
              "target                                                                      \n",
              "0        4342       1854       1396       1092  0.426992  0.321511  0.251497\n",
              "1        3271       1881        537        853  0.575054  0.164170  0.260777"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc52fcdb-117a-4747-935f-1811b3240124\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total</th>\n",
              "      <th>negativos</th>\n",
              "      <th>positivos</th>\n",
              "      <th>neutrales</th>\n",
              "      <th>p_neg</th>\n",
              "      <th>p_pos</th>\n",
              "      <th>p_neu</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4342</td>\n",
              "      <td>1854</td>\n",
              "      <td>1396</td>\n",
              "      <td>1092</td>\n",
              "      <td>0.426992</td>\n",
              "      <td>0.321511</td>\n",
              "      <td>0.251497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3271</td>\n",
              "      <td>1881</td>\n",
              "      <td>537</td>\n",
              "      <td>853</td>\n",
              "      <td>0.575054</td>\n",
              "      <td>0.164170</td>\n",
              "      <td>0.260777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc52fcdb-117a-4747-935f-1811b3240124')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc52fcdb-117a-4747-935f-1811b3240124 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc52fcdb-117a-4747-935f-1811b3240124');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8d9b5821-3e38-4121-b3af-87bdd61d0885\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d9b5821-3e38-4121-b3af-87bdd61d0885')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8d9b5821-3e38-4121-b3af-87bdd61d0885 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ef3aef70-0625-4de5-bbda-32d1539c85bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ef3aef70-0625-4de5-bbda-32d1539c85bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 757,\n        \"min\": 3271,\n        \"max\": 4342,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3271,\n          4342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 1854,\n        \"max\": 1881,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1881,\n          1854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positivos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 607,\n        \"min\": 537,\n        \"max\": 1396,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          537,\n          1396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutrales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168,\n        \"min\": 853,\n        \"max\": 1092,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          853,\n          1092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_neg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10469517114726591,\n        \"min\": 0.4269921695071396,\n        \"max\": 0.5750535004585754,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5750535004585754,\n          0.4269921695071396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_pos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1112567790970672,\n        \"min\": 0.16416997859981658,\n        \"max\": 0.3215108245048365,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.16416997859981658,\n          0.3215108245048365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_neu\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00656160794980132,\n        \"min\": 0.25149700598802394,\n        \"max\": 0.2607765209416081,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.2607765209416081,\n          0.25149700598802394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tasa de negativos en NO DESASTRE (0): 0.427\n",
            "Tasa de negativos en DESASTRE (1):   0.575\n",
            "Diferencia (1 - 0): +0.148\n",
            "\n",
            "=== Chi-cuadrado sentimiento x categoría ===\n",
            "sent_label  negative  neutral  positive\n",
            "target                                 \n",
            "0               1854     1092      1396\n",
            "1               1881      853       537\n",
            "chi2=265.885, dof=2, p-value=1.836e-58, Cramér's V=0.187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Punto 10: Variable \"negatividad\" + reentrenar y comparar ===\n",
        "# Definición de negatividad: usamos sent_neg (proporción negativa de VADER), rango [0,1].\n",
        "# Comparamos SVM (texto) vs SVM (texto + negatividad) con el MISMO split (X_train/X_test).\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "\n",
        "# --- 0) Chequeos y preparación\n",
        "assert 'sent_neg' in df.columns, \"Ejecuta primero la Parte 8 (VADER) para tener 'sent_neg'.\"\n",
        "\n",
        "# Variable de negatividad (0..1)\n",
        "df['negatividad'] = df['sent_neg'].fillna(0.0)\n",
        "\n",
        "text_col   = 'clean_text' if 'clean_text' in df.columns else 'text'\n",
        "target_col = 'target'\n",
        "\n",
        "# Reusar el MISMO split que ya hiciste en el punto 6\n",
        "if not all(k in globals() for k in ['X_train','X_test','y_train','y_test']):\n",
        "    raise RuntimeError(\"No encuentro X_train/X_test del punto 6. Ejecuta primero el bloque del punto 6.\")\n",
        "\n",
        "idx_tr = X_train.index\n",
        "idx_te = X_test.index\n",
        "\n",
        "Xtr_text = df.loc[idx_tr, text_col].astype(str)\n",
        "Xte_text = df.loc[idx_te, text_col].astype(str)\n",
        "ytr = y_train.astype(int)\n",
        "yte = y_test.astype(int)\n",
        "\n",
        "# --- 1) Vectorizador texto (mismos hiperparámetros del punto 6)\n",
        "vec = TfidfVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.98,\n",
        "    strip_accents='unicode',\n",
        "    lowercase=True\n",
        ")\n",
        "Xtr_tfidf = vec.fit_transform(Xtr_text)\n",
        "Xte_tfidf = vec.transform(Xte_text)\n",
        "\n",
        "# --- 2) BASELINE: SVM con texto solamente\n",
        "svm_base = LinearSVC()\n",
        "grid_base = GridSearchCV(\n",
        "    svm_base,\n",
        "    {'C': [0.5, 1.0, 2.0]},\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "grid_base.fit(Xtr_tfidf, ytr)\n",
        "yhat_base = grid_base.predict(Xte_tfidf)\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0\n",
        "    )\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "m_base = metrics(yte, yhat_base)\n",
        "\n",
        "# --- 3) EXTENDIDO: concatenar negatividad como feature numérica (sparse) al TF-IDF\n",
        "Xtr_neg = csr_matrix(df.loc[idx_tr, 'negatividad'].values.reshape(-1,1))\n",
        "Xte_neg = csr_matrix(df.loc[idx_te, 'negatividad'].values.reshape(-1,1))\n",
        "\n",
        "Xtr_aug = hstack([Xtr_tfidf, Xtr_neg], format='csr')\n",
        "Xte_aug = hstack([Xte_tfidf, Xte_neg], format='csr')\n",
        "\n",
        "svm_aug = LinearSVC()\n",
        "grid_aug = GridSearchCV(\n",
        "    svm_aug,\n",
        "    {'C': [0.5, 1.0, 2.0]},\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "grid_aug.fit(Xtr_aug, ytr)\n",
        "yhat_aug = grid_aug.predict(Xte_aug)\n",
        "\n",
        "m_aug = metrics(yte, yhat_aug)\n",
        "\n",
        "# --- 4) Resumen comparativo\n",
        "comp = pd.DataFrame(\n",
        "    {\n",
        "        \"modelo\": [\"SVM texto\", \"SVM texto+negatividad\"],\n",
        "        \"C_best\": [grid_base.best_params_['C'], grid_aug.best_params_['C']],\n",
        "        \"accuracy\": [m_base[0], m_aug[0]],\n",
        "        \"precision\": [m_base[1], m_aug[1]],\n",
        "        \"recall\": [m_base[2], m_aug[2]],\n",
        "        \"f1\": [m_base[3], m_aug[3]],\n",
        "    }\n",
        ").round(4)\n",
        "comp[\"Δ_accuracy\"] = (comp.loc[1,\"accuracy\"] - comp.loc[0,\"accuracy\"]).round(4)\n",
        "comp[\"Δ_recall\"]   = (comp.loc[1,\"recall\"]   - comp.loc[0,\"recall\"]).round(4)\n",
        "comp[\"Δ_f1\"]       = (comp.loc[1,\"f1\"]       - comp.loc[0,\"f1\"]).round(4)\n",
        "comp\n",
        "\n",
        "print(\"\\n== Reporte del modelo EXTENDIDO (texto+negatividad) ==\")\n",
        "print(f\"Mejor C: {grid_aug.best_params_['C']}\")\n",
        "print(classification_report(yte, yhat_aug, digits=4))\n",
        "print(\"Matriz de confusión (extendido):\")\n",
        "print(confusion_matrix(yte, yhat_aug))\n",
        "\n",
        "# --- 5) Guardar el modelo extendido para usarlo si lo quieres en una versión v2 de clasificador\n",
        "import joblib\n",
        "artifacts = {\n",
        "    \"vectorizer\": vec,\n",
        "    \"svm\": grid_aug.best_estimator_,\n",
        "    \"C\": grid_aug.best_params_['C'],\n",
        "    \"note\": \"Este modelo espera TF-IDF de texto + una columna extra con negatividad (sent_neg).\"\n",
        "}\n",
        "joblib.dump(artifacts, \"modelo_disaster_withneg.joblib\")\n",
        "print(\"\\nModelo extendido guardado en: modelo_disaster_withneg.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb_CCe-Us2jG",
        "outputId": "0b1b8409-e10c-4108-8e25-3c940f3c86dd"
      },
      "id": "Lb_CCe-Us2jG",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Reporte del modelo EXTENDIDO (texto+negatividad) ==\n",
            "Mejor C: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8187    0.8677    0.8425       869\n",
            "           1     0.8090    0.7446    0.7755       654\n",
            "\n",
            "    accuracy                         0.8148      1523\n",
            "   macro avg     0.8138    0.8062    0.8090      1523\n",
            "weighted avg     0.8145    0.8148    0.8137      1523\n",
            "\n",
            "Matriz de confusión (extendido):\n",
            "[[754 115]\n",
            " [167 487]]\n",
            "\n",
            "Modelo extendido guardado en: modelo_disaster_withneg.joblib\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}